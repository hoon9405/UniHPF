diff --git a/.gitignore b/.gitignore
old mode 100644
new mode 100755
index b6e4761..9afa528
--- a/.gitignore
+++ b/.gitignore
@@ -127,3 +127,13 @@ dmypy.json
 
 # Pyre type checker
 .pyre/
+*.fasta
+*.pkl
+__pycache__/
+checkpoints/
+results/
+*.fasta
+*.pkl
+.vscode/
+wandb/
+*.pt
\ No newline at end of file
diff --git a/Dockerfile b/Dockerfile
old mode 100644
new mode 100755
diff --git a/LICENSE b/LICENSE
old mode 100644
new mode 100755
diff --git a/README.md b/README.md
old mode 100644
new mode 100755
diff --git a/datasets/__init__.py b/datasets/__init__.py
old mode 100644
new mode 100755
index 4d383a2..3102fe0
--- a/datasets/__init__.py
+++ b/datasets/__init__.py
@@ -1,14 +1,10 @@
 from .base_dataset import (
     HierarchicalEHRDataset,
-    UnifiedEHRDataset,
-    NoteDataset
+    FlattenEHRDataset,
 )
 
-#from .benchmark_dataset import BenchmarkDataset
 
 __all__ = [
     'HierarchicalEHRDataset',
-    'UnifiedEHRDataset',
-    'NoteDataset',
-    'BenchmarkDataset'
+    'FlattenEHRDataset',
 ]
\ No newline at end of file
diff --git a/datasets/base_dataset.py b/datasets/base_dataset.py
old mode 100644
new mode 100755
index 1fda6ed..cb6b1b7
--- a/datasets/base_dataset.py
+++ b/datasets/base_dataset.py
@@ -5,57 +5,74 @@ import random
 import collections
 
 import torch
+import torch.nn.functional as F
 import torch.utils.data
 import tqdm
 import numpy as np
 import pandas as pd
 
 from transformers import AutoTokenizer
+from sklearn.preprocessing import MultiLabelBinarizer
+np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)
 
 logger = logging.getLogger(__name__)
 
+# Dataset created from https://github.com/Jwoo5/integrated-ehr-pipeline
+
+# 1. set input / fold directory
+# 2. input split icustay ids (get fold indices)
+# 3. masking functions (should i leave it here?)
+# 4. label loading
 class BaseEHRDataset(torch.utils.data.Dataset):
     def __init__(
         self,
         data,
+        emb_type,
+        feature,
         input_path,
         split,
-        concept='descemb',
-        feature='entire',
+        structure,
         train_task=None,
         ratio='100',   
         seed='2020',
         **kwargs,
     ):
-        self.base_path = os.path.join(input_path, icu_type, data)
-        self.feature = feature
+        self.data_dir = os.path.join(input_path, data, emb_type, feature) #TODO: data sampling dir
+        
+        self.stay_id = {
+            "mimiciii": "ICUSTAY_ID",
+            "eicu": "patientunitstayid",
+            "mimiciv": "stay_id"
+        }[data]
 
-        self.concept = concept
-        self.structure = 'hi' if '_' in concept else 'fl'
-        self.root = concept.split('_')[0]
+        self.split = split
 
+        self.structure = structure
         self.train_task = train_task
 
-        self.seed = seed
-        self.split = split
-
-                
         self.seed = seed
 
-        self.data_dir = os.path.join(
-            self.base_path, self.feature, self.root, self.structure
-        )
-
-        #self.time_bucket_idcs = [idx for idx in range(6, 6+20+1)] #start range + bucket num + 1
-        self.time_bucket_idcs = [idx for idx in range(4, 24)] #start range + bucket num + 1
-        self.fold_file = os.path.join(
-            self.base_path, "fold", "fold_{}.csv".format(ratio)
-        )
-
-        assert self.root in ['codeemb', 'descemb'], (
-            'please ensure --concept starts one of ["codeemb", "descemb"] '
-            '--concept: {}'.format(concept)
-        )
+        # Get split icustay ids
+        self.fold_file = pd.read_csv(os.path.join(input_path, f"{data}_cohort.csv"))
+       
+        # If pretrain, use train-valid data of 5 seeds
+        if 'pretrain' in self.train_task and self.split == 'train':
+            self.train_valid_idcs = np.array([])
+            self.test_idcs = np.array([])
+            for seed in self.seed:
+                col_name = f'split_{seed}'
+                self.train_valid_idcs = np.append(self.train_valid_idcs, self.fold_file[self.fold_file[col_name] == 'train'][self.stay_id].values)
+                self.train_valid_idcs = np.append(self.train_valid_idcs, self.fold_file[self.fold_file[col_name] == 'valid'][self.stay_id].values)
+                self.test_idcs = np.append(self.test_idcs, self.fold_file[self.fold_file[col_name] == 'test'][self.stay_id].values)
+            
+            self.hit_idcs = np.unique(self.train_valid_idcs[~np.isin(self.train_valid_idcs, self.test_idcs)])
+
+        # If scratch / finetune, use train/valid/test data of 1 seed each
+        elif self.train_task in ['scratch', 'finetune']:
+            col_name = f'split_{seed[0]}'
+            self.hit_idcs = self.fold_file[self.fold_file[col_name] == self.split][self.stay_id].values
+
+        logger.info(f'loaded {len(self.hit_idcs)} {self.split} samples')
 
     def __len__(self):
         raise NotImplementedError
@@ -63,61 +80,32 @@ class BaseEHRDataset(torch.utils.data.Dataset):
     def __getitem__(self, index):
         raise NotImplementedError
 
-    def get_fold_indices(self, return_all=False):
-        if self.split == 'train':
-            hit = 1
-        elif self.split == 'valid':
-            hit = 2
-        elif self.split == 'test':
-            hit = 0
-
-        df = pd.read_csv(self.fold_file)
-        if return_all:
-            return np.arange(len(df))
-        
-        if self.train_task =='predict':
-            col_name = self.pred_target + '_' + self.seed + '_strat'
-
-        elif self.train_task=='pretrain':
-            col_name = str(self.seed) + '_rand'
-            if self.split =='train':
-                df.loc[df[col_name] == 0, col_name] = 1
-
-        splits = df[col_name].values
-        idcs = np.where(splits == hit)[0]
-    
-        return idcs
-    
-    def get_num_events(self):
-        df = pd.read_csv(self.fold_file)
-
-        return df['num_events'].values
-
-    def mask_tokens(self, inputs: torch.Tensor, mask_vocab_size : int, 
-                    mask_token : int, special_tokens_mask: torch.Tensor, masked_indices=None):
+    def mask_tokens(self, inputs: np.array, mask_vocab_size : int, 
+                    mask_token : int, is_tokenized: bool, masked_indices=None):
         """
         Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.
         """
         inputs = torch.LongTensor(inputs)
         labels = inputs.clone()
-        # We sample a few tokens in each sequence for MLM training (with probability `self.textencoder_mlm_probability`)
-        probability_matrix = torch.full(labels.shape, self.mlm_prob)
 
-        if 'descemb' in self.concept:
+        probability_matrix = torch.full(labels.shape, self.mlm_prob)
+        
+        if is_tokenized: #TODO: flatten 에도 적용하기
             special_tokens_mask = torch.tensor(
                 self.tokenizer.get_special_tokens_mask(
                     labels, already_has_special_tokens=True
                 ),
                 dtype=torch.bool
             )
-        else:
-            special_tokens_mask = (inputs== 0 )| (inputs ==1) | (inputs ==2)
-        
-        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)
+            probability_matrix.masked_fill_(special_tokens_mask, value=0.0)
+        else: # Mask cls, sep for type/dpe ids (hierarchical)
+            probability_matrix[0] = 0.0
+            probability_matrix[-1] = 0.0
+
         if masked_indices is None:
             masked_indices = torch.bernoulli(probability_matrix).bool()
 
-            while torch.equal(masked_indices, torch.zeros(len(masked_indices)).bool()):
+            while torch.equal(masked_indices, torch.zeros(len(masked_indices)).bool()): #TODO: 여기서 걸린거로 생각됨
                 masked_indices = torch.bernoulli(probability_matrix).bool()
 
         labels[~masked_indices] = -100  # We only compute loss on masked tokens
@@ -133,6 +121,21 @@ class BaseEHRDataset(torch.utils.data.Dataset):
         # The rest of the time (10% of the time) we keep the masked input tokens unchanged
         return inputs.numpy(), labels.numpy()
 
+
+    def hi_mask_tokens_wrapper(self, inputs: list, mask_vocab_size : int, 
+                    mask_token : int, is_tokenized: bool, masked_indices=None):
+        
+        masked_events = []
+        masked_labels = []
+        for event in inputs:
+            masked_event, masked_label = self.mask_tokens(event, mask_vocab_size,
+                                                        mask_token, is_tokenized, masked_indices)
+            masked_events.append(masked_event)
+            masked_labels.append(masked_label)
+        
+        return masked_events, masked_labels
+
+
     def span_masking(self, inputs: torch.Tensor, mask_vocab_size : int, 
                         mask_token : int, special_tokens_mask: torch.Tensor, masked_indices=None):
         """
@@ -164,146 +167,72 @@ class EHRDataset(BaseEHRDataset):
     def __init__(
         self,
         data,
+        emb_type,
+        feature,
         input_path,
         split,
-        vocab,
-        concept='descemb',
-        feature='entire',
         train_task=None,
-        pretrain_task=None,
         ratio='100',
-        pred_target='mort',
+        pred_tasks = None,
         seed='2020',
-        mask_list='input, type',
+        mask_list=['input', 'type', 'dpe'],
         mlm_prob=0.3,
-        activate_fold=True,
-        reload=False,
+        pretrain_task=None,
         **kwargs,
     ):
         super().__init__(
             data=data,
+            emb_type=emb_type,
+            feature=feature,
             input_path=input_path,
             split=split,
-            concept=concept,
-            feature=feature,
             train_task=train_task,
             ratio=ratio,
-            icu_type=icu_type,
-            split_method=split_method,
             seed=seed,
             **kwargs,
         )
 
-        self.vocab = vocab
-
-        self.pred_target = pred_target
+        self.pred_tasks = pred_tasks
+        self.pretrain_task = pretrain_task
 
         self.tokenizer = None
-        self.mask = None
-        if (
-            self.train_task == 'pretrain'
-            and pretrain_task in ['mlm', 'spanmlm']
-            and self.structure == 'fl'
-        ):
-            self.tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
-            self.mask = self.span_masking if pretrain_task=='spanmlm' else self.mask_tokens
 
+        if 'pretrain' in self.train_task:
+            self.tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
+        
+        self.mask = None
         self.mask_list = mask_list
         self.mlm_prob = mlm_prob
-        label = np.load(
-            os.path.join(
-                self.base_path, 'label', pred_target + '.npy'
-            ), allow_pickle=True
-        )
-        self.label = torch.tensor(label, dtype=torch.long)
-
-        self.num_events = self.get_num_events()
-        if activate_fold:
-            self.hit_idcs = self.get_fold_indices()
-            self.num_events = self.num_events[self.hit_idcs]
-            self.label = self.label[self.hit_idcs]
-
-        input_index_size_dict = {
-                            'mimic3' : {
-                                'select' : 6532,
-                                'entire' :10389
-                            },
-                            'eicu' : {
-                                'select' : 4151,
-                                'entire' : 6305
-                            },
-                            'mimic4' : {
-                                'select' : 5581,
-                                'entire' : 9568
-                            }
-        } 
-
-        type_index_size_dict = {
-                            'mimic3' : {
-                                'select' : 9,
-                                'entire' :10
-                            },
-                            'eicu' : {
-                                'select' : 10,
-                                'entire' :10
-                            },
-                            'mimic4' : {
-                                'select' : 10,
-                                'entire' :9
-                            }
-        }
 
-        self.mask_vocab_size = None
-        self.mask_token = None
-        if self.mask:
-            if 'codeemb' in concept:
-                self.mask_vocab_size = {
-                    'input': input_index_size_dict[data][feature]-1,
-                    'type': type_index_size_dict[data][feature]-1
-                }
-            else:
-                self.mask_vocab_size = {
-                    'input' : 28117,
-                    'type' : 12,
-                     'dpe' : 23
-                    }            
-
-            if 'codeemb' in self.concept:
-               self.mask_token = {
-                   'input': 3,
-                    'type': 3,
-                    }
-            else:
-                self.mask_token = {
-                    'input': 103,
-                    'type': 3,
-                    'dpe': 1,
-                }
-        if not reload:
-            logger.info(f'loaded {len(self.hit_idcs)} {self.split} samples')
+        self.mask_vocab_size = { 
+            'input' : 28996,
+            'type' : 7, # 0-6 (pad, cls, sep 포함)
+            'dpe' : 16 # 0 - 14, 15 mask (mimic3,eicu,mimic4)
+            }            
+        
+        self.mask_token = { # 안쓰이는 토큰
+            'input': 103,
+            'type': 4, #TODO: need modification if use time bucket 
+            'dpe': 15, 
+        }
 
     def __len__(self):
         return len(self.hit_idcs)
 
+
 class HierarchicalEHRDataset(EHRDataset):
-    def __init__(self, max_word_len=256, max_seq_len=512, **kwargs):
+    def __init__(self, max_seq_len=256, max_word_len=128, **kwargs):
         super().__init__(**kwargs)
 
-        self.max_word_len = max_word_len
         self.max_seq_len = max_seq_len
-        
-        self.cls = 101 if self.concept.startswith('descemb') else 1
+        self.max_word_len = max_word_len
 
-    def crop_to_max_size(self, arr, target_size):
-        """
-        arr: 1d np.array of indices
-        """
-        size = len(arr)
-        diff = size - target_size
-        if diff <= 0:
-            return arr
+        if 'pretrain' in self.train_task:
+            if self.pretrain_task in ['simclr']:
+                self.mask = self.hi_mask_tokens_wrapper
 
-        return arr[:target_size]
+    def __len__(self):
+        return len(self.hit_idcs)
 
     def collator(self, samples):
         samples = [s for s in samples if s['input_ids'] is not None]
@@ -313,55 +242,44 @@ class HierarchicalEHRDataset(EHRDataset):
         input = dict()
         out = dict()
 
-        input['input_ids'] = [s['input_ids'] for s in samples]
-        input['type_ids'] = [s['type_ids'] for s in samples]
-        if 'descemb' in self.concept:
+        if 'pretrain' in self.train_task and self.pretrain_task == "simclr":
+            input['input_ids'] = [j.astype(np.int16) for s in samples for j in s['input_ids']]
+            input['type_ids'] = [j.astype(np.int16) for s in samples for j in s['type_ids']]
+            input['dpe_ids'] = [j.astype(np.int16) for s in samples for j in s['dpe_ids']]
+        else:
+            input['input_ids'] = [s['input_ids'] for s in samples]
+            input['type_ids'] = [s['type_ids'] for s in samples]
             input['dpe_ids'] = [s['dpe_ids'] for s in samples]
-        
+
+        # Pad events for fixed event count per batch
+        # Words per event already padded to max_word_len on data creation
         seq_sizes = []
-        word_sizes = []
         for s in input['input_ids']:
-            seq_sizes.append(len(s))
-            for w in s:
-                word_sizes.append(len(w))
-
+           seq_sizes.append(len(s))
 
-        target_seq_size = min(max(seq_sizes), self.max_seq_len) #min 값 골라서 그거 기준으로 max 잡음
-        target_word_size = min(max(word_sizes), self.max_word_len) 
+        target_seq_size = min(max(seq_sizes), self.max_seq_len) 
 
         collated_input = dict()
         for k in input.keys():
             collated_input[k] = torch.zeros(
-                (len(input['input_ids']), target_seq_size, target_word_size,)
+                (len(input['input_ids']), target_seq_size, self.max_word_len,)
             ).long()
  
         for i, seq_size in enumerate(seq_sizes):
-            for j in range(len(input['input_ids'][i])):
-                word_size = len(input['input_ids'][i][j])
-                diff = word_size - target_word_size
-                for k in input.keys():
-                    if diff == 0:
-                        pass
-                    elif diff < 0:
-                        try:
-                            input[k][i][j] = np.append(input[k][i][j], [0] * -diff)
-                        except ValueError:
-                            input[k][i] = list(input[k][i])
-                            input[k][i][j] = np.append(input[k][i][j], [0] * -diff)
-                    else:
-                        input[k][i][j] = np.array(input[k][i][j][:self.max_word_len])
 
             diff = seq_size - target_seq_size
             for k in input.keys():
                 if k == 'input_ids':
-                    prefix = self.cls
-                else:
-                    prefix = 1
-                input[k][i] = np.array(list(input[k][i]))
+                    prefix = 101
+                elif k == "type_ids":
+                    prefix = 5 
+                elif k == "dpe_ids":
+                    prefix = 0
+
                 if diff == 0:
                     collated_input[k][i] = torch.from_numpy(input[k][i])
                 elif diff < 0:
-                    padding = np.zeros((-diff, target_word_size - 1,))
+                    padding = np.zeros((-diff, self.max_word_len - 1,))
                     padding = np.concatenate(
                         [np.full((-diff, 1), fill_value=prefix), padding], axis=1
                     )
@@ -370,36 +288,125 @@ class HierarchicalEHRDataset(EHRDataset):
                             [input[k][i], padding], axis=0
                         )
                     )
-                else:
-                    collated_input[k][i] = torch.from_numpy(
-                        self.crop_to_max_size(input[k][i], target_seq_size)
-                    )
+
+        #TODO: 위와 코드 로직 합치기
+        if 'pretrain' in self.train_task and self.pretrain_task == "simclr":
+            collated_input['times'] = torch.from_numpy(np.stack([self.pad_to_max_size(j.astype(np.float64), target_seq_size) for s in samples for j in s['times']]))
+        else:
+            collated_input['times'] = torch.from_numpy(np.stack([self.pad_to_max_size(s['times'], target_seq_size) for s in samples]))
 
         out['net_input'] = collated_input
-        if 'label' in samples[0]:
-            out['label'] = torch.stack([s['label'] for s in samples])
+
+        if 'labels' in samples[0].keys():
+            label_dict = dict()
+
+            for k in samples[0]['labels'].keys():
+                label_dict[k] = torch.stack([s['labels'][k] for s in samples])
+            
+            out['labels'] = label_dict
+            
+            out['icustays'] = [s['icustays'] for s in samples]
 
         return out
 
-    def __getitem__(self, index):
-        num_event = self.num_events[index]
-        fname = str(self.hit_idcs[index]) + '.npy'
+    def pad_to_max_size(self, sample, max_len):
+        if len(sample) < max_len:
+            sample = np.concatenate(
+                [sample, np.zeros(max_len - len(sample), dtype=np.int16)]
+            )
+        return sample
 
-        input_ids = np.load(os.path.join(self.data_dir, 'input_ids', fname), allow_pickle=True)
-        type_ids = np.load(os.path.join(self.data_dir, 'type_ids', fname), allow_pickle=True)
-        dpe_ids = None
-        if self.concept.startswith('descemb'):
-            dpe_ids = np.load(os.path.join(self.data_dir, 'dpe_ids', fname), allow_pickle=True)
-        label = self.label[index]
-
-        out = {
-            'input_ids': input_ids[-num_event:],
-            'type_ids': type_ids[-num_event:],
-            'dpe_ids': dpe_ids[-num_event:] if dpe_ids is not None else None,
-            'label': label,
+    def __getitem__(self, index):
+        fname = str(int(self.hit_idcs[index])) + '.pkl' #TODO: modify data pipeline cohort icustay type to int 
+        data = pd.read_pickle(os.path.join(self.data_dir, fname))
+
+        pack = {
+            'input_ids': data[self.structure][:, 0, :],
+            'type_ids': data[self.structure][:, 1, :],
+            'dpe_ids': data[self.structure][:, 2, :],
+            'times': data['time'],
         }
+        
+        # Labels
+        if self.train_task in ["scratch", "finetune"]: 
+            labels = dict()
+            for task in self.pred_tasks:
+                task_name = task.name
+                task_prop = task.property
+                task_class = task.num_classes
+                labels[task_name] = self.fold_file[self.fold_file[self.stay_id] == self.hit_idcs[index]][task_name].values[0]
+                if task_prop == "binary":
+                    labels[task_name] = torch.tensor(labels[task_name], dtype=torch.float32)
+                
+                elif task_prop == "multi-label":
+                    if task_name == 'diagnosis':
+                        if labels[task_name] == -1 or labels[task_name]=='[]':
+                            labels[task_name] = torch.zeros(task_class, dtype=torch.float32)
+                            #labels[task_name] = torch.tensor([-100]*task_class, dtype=torch.float32)
+                        else:
+                            labels[task_name] = eval(labels[task_name]) #[3,5,2,1]
+                            labels[task_name] = F.one_hot(torch.tensor(labels[task_name], dtype=torch.int64), num_classes=task_class).sum(dim=0).to(torch.float32)
+     
+                elif task_prop == "multi-class":
+                    # Missing values are filled with -1 or Nan
+                    if labels[task_name] == -1 or np.isnan(labels[task_name]):
+                        labels[task_name] = torch.zeros(task_class).to(torch.float32)
+                        #labels[task_name] = torch.torch.tensor(-100, dtype=torch.int64)
+                    else:
+                        labels[task_name] = F.one_hot(torch.tensor(labels[task_name]).to(torch.int64), num_classes=task_class).to(torch.float32)
+                        #labels[task_name] = torch.tensor(labels[task_name], dtype=torch.int64)
+
+            pack['labels'] = labels
+            pack['icustays'] = self.hit_idcs[index]
+
+        # Apply masking
+        if self.mask:
+            masked_indices = None
+
+            input_ids = pack['input_ids']
+            type_ids = pack['type_ids']
+            dpe_ids = pack['dpe_ids']
+
+            pack_no_pad = {
+                'input_ids': [],
+                'type_ids': [],
+                'dpe_ids': [],
+            }
+
+            for input_id, type_id, dpe_id in zip(input_ids, type_ids, dpe_ids):
+                input_id = input_id[input_id != 0]
+                type_id = type_id[:len(input_id)]
+                dpe_id = dpe_id[:len(input_id)]
+
+                pack_no_pad['input_ids'].append(input_id)
+                pack_no_pad['type_ids'].append(type_id)
+                pack_no_pad['dpe_ids'].append(dpe_id)
+
+            for victim in self.mask_list:
+                is_tokenized = True if victim == 'input_ids' else False
+
+                victim_ids, _ = self.mask( 
+                    inputs=pack_no_pad[victim + "_ids"], 
+                    mask_vocab_size=self.mask_vocab_size[victim],
+                    mask_token=self.mask_token[victim],
+                    is_tokenized=is_tokenized,
+                    masked_indices=masked_indices
+                )
+
+                victim_ids = [self.pad_to_max_size(victim_id, self.max_word_len) for victim_id in victim_ids]
+                victim_ids = np.stack(victim_ids).astype(np.int16)
+
+                pack[victim + "_ids"] = victim_ids
+
+            # Halve events when SimCLR pre-training
+            if 'pretrain' in self.train_task and self.pretrain_task == 'simclr':
+                for victim in self.mask_list:
+                    half = int(len(pack[victim + "_ids"]) / 2)
+                    pack[victim + "_ids"] = np.array([pack[victim + "_ids"][:half], pack[victim + "_ids"][half:]], dtype=object)
+                pack['times'] = np.array([pack['times'][:half], pack['times'][half:]], dtype=object)
+
+        return pack
 
-        return out
 
 class FlattenEHRDataset(EHRDataset):
     def __init__(self, max_seq_len=8192, **kwargs):
@@ -407,6 +414,10 @@ class FlattenEHRDataset(EHRDataset):
 
         self.max_seq_len = max_seq_len
 
+        if 'pretrain' in self.train_task:
+            if self.pretrain_task in ['mlm', 'spanmlm', 'simclr']:
+                self.mask = self.span_masking if self.pretrain_task=='spanmlm' else self.mask_tokens
+
         self.time_token = 4
        
     def crop_to_max_size(self, arr, target_size):
@@ -442,20 +453,24 @@ class FlattenEHRDataset(EHRDataset):
         input = dict()
         out = dict()
 
-        input['input_ids'] = [s['input_ids'] for s in samples]
-        input['type_ids'] = [s['type_ids'] for s in samples]
-        if self.concept.startswith('descemb'):
+        if self.pretrain_task == "simclr": # Make positive pair adjacent (B -> 2*B)
+            input['input_ids'] = [j for s in samples for j in s['input_ids']]
+            input['type_ids'] = [j for s in samples for j in s['type_ids']]
+            input['dpe_ids'] = [j for s in samples for j in s['dpe_ids']]
+        else:
+            input['input_ids'] = [s['input_ids'] for s in samples]
+            input['type_ids'] = [s['type_ids'] for s in samples]
             input['dpe_ids'] = [s['dpe_ids'] for s in samples]
 
         if self.mask:
             for victim in self.mask_list:
-                input[victim+'_label']= [s[victim+'_label'] for s in samples]
+                if self.pretrain_task == "simclr":
+                    input[victim+'_label']= [j for s in samples for j in s[victim+'_label']]
+                else:
+                    input[victim+'_label']= [s[victim+'_label'] for s in samples]
 
         sizes = [len(s) for s in input['input_ids']]
-        if self.args.pred_model =='cnn':
-            target_size = self.max_seq_len
-        else:
-            target_size = min(max(sizes), self.max_seq_len) # target size
+        target_size = min(max(sizes), self.max_seq_len) # target size
 
         collated_input = dict()
         for k in input.keys():
@@ -484,22 +499,27 @@ class FlattenEHRDataset(EHRDataset):
         return out
 
     def __getitem__(self, index):
-        num_event = self.num_events[index]
         fname = str(self.hit_idcs[index]) + '.npy'
 
         input_ids = np.load(os.path.join(self.data_dir, 'input_ids', fname), allow_pickle=True)
         type_ids = np.load(os.path.join(self.data_dir, 'type_ids', fname), allow_pickle=True)
-        dpe_ids = None
-        if self.concept.startswith('descemb'):
-            dpe_ids = np.load(os.path.join(self.data_dir, 'dpe_ids', fname), allow_pickle=True)
-        label = self.label[index]
-
-        out = {
-            'input_ids': input_ids,
-            'type_ids': type_ids,
-            'dpe_ids': dpe_ids if dpe_ids is not None else None,
-            'label': label,
-        }
+        dpe_ids = np.load(os.path.join(self.data_dir, 'dpe_ids', fname), allow_pickle=True)
+        
+        if self.train_task in['scratch', 'finetune']:
+            label = self.label[index]
+
+            out = {
+                'input_ids': input_ids,
+                'type_ids': type_ids,
+                'dpe_ids': dpe_ids,
+                'label': label,
+            }
+        else:
+            out = {
+                'input_ids': input_ids,
+                'type_ids': type_ids,
+                'dpe_ids': dpe_ids,
+            }
 
         if self.mask:
             masked_indices = None
@@ -520,14 +540,15 @@ class FlattenEHRDataset(EHRDataset):
                 np.array(type_ids) == self.time_token
             )[0]
 
-            if len(time_token_idcs) == num_event:
-                onset = 0
-            else:
-                onset = time_token_idcs[-num_event - 1] + 1
+        if self.pretrain_task == "simclr":
+            unique, counts = np.unique(type_ids, return_counts=True)
+            half_event_count = int(dict(zip(unique, counts))[4]/2)
+            half_len = [i_i for i_i, n_i in enumerate(type_ids) if n_i == 4][half_event_count - 1]
+            for victim in ['input', 'type', 'dpe']:
+                out[victim + '_ids'] = np.array([out[victim + '_ids'][:half_len+1], out[victim + '_ids'][half_len+1:]])
+                if victim in self.mask_list:
+                    out[victim + '_label'] = np.array([out[victim + '_label'][:half_len+1], out[victim + '_label'][half_len+1:]])
 
-            out['input_ids'] = out['input_ids'][onset:]
-            out['type_ids'] = out['type_ids'][onset:]
-            if dpe_ids is not None:
-                out['dpe_ids'] = out['dpe_ids'][onset:]
 
         return out
+
diff --git a/env.yaml b/env.yaml
old mode 100644
new mode 100755
diff --git a/loss/__init__.py b/loss/__init__.py
deleted file mode 100644
index 63f9f8a..0000000
--- a/loss/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-from .loss import (
-    BaseLoss,
-    PredLoss,
-    PretrainLoss,
-    NoteLoss
-)
-
-__all__ = [
-    BaseLoss,
-    PredLoss,
-    PretrainLoss,
-    NoteLoss
-]
\ No newline at end of file
diff --git a/loss/loss.py b/loss/loss.py
deleted file mode 100644
index 7435148..0000000
--- a/loss/loss.py
+++ /dev/null
@@ -1,99 +0,0 @@
-from tkinter.messagebox import NO
-from tkinter import N
-from builtins import NotImplemented
-import torch.nn.functional as F
-import torch.nn as nn
-
-
-
-class BaseLoss():
-    def __init__(self, args):
-        self.args = args
-        self.BCE_loss = nn.BCEWithLogitsLoss()
-        self.CE_loss = nn.CrossEntropyLoss()
-
-    def __call__(self):
-        return None
-
-
-class PredLoss(BaseLoss):
-    def __init__(self, args):
-        super().__init__(args=args)
-        self.args = args
-        self.multi_label_dict = {
-            'mimic3':{
-                'dx':18,
-                'im_disch':17,
-                'fi_ac':18},
-            'eicu':{
-                'dx':18,
-                'im_disch':8,
-                'fi_ac':9},
-             'mimic4':{
-                'dx':18,
-                'im_disch':17,
-                'fi_ac':18},
-            }
-    def __call__(self, output, target):
-        if self.args.pred_target in ['mort', 'los3', 'los7', 'readm']:
-            return self.binary_class(output, target)
-
-        elif self.args.pred_target in ['im_disch', 'fi_ac']:
-            return self.multi_class(output, target)
-
-        elif self.args.pred_target in ['dx']:
-            return self.multi_label_multi_class(output, target)
-
-
-    def binary_class(self, output, target):
-        return self.BCE_loss(output['pred_output'], 
-                            target.to(output['pred_output'].device)
-                            )
-    
-    def multi_class(self, output, target):
-        return self.CE_loss(
-            output['pred_output'], F.one_hot(
-            target.long(), 
-            self.multi_label_dict[self.args.src_data][self.args.pred_target]
-            ).float().to(output['pred_output'].device)
-            )
-
-    def multi_label_multi_class(self, output, target):
-        return self.BCE_loss(
-            output['pred_output'].view(-1), 
-            target.view(-1).to(output['pred_output'].device)
-            )
-    
-
-class PretrainLoss(BaseLoss):
-    def __init__(self, args):
-        super().__init__(args=args)
-        self.args = args
-
-
-    def __call__(self, output, target):
-        if self.args.pretrain_task in ['mlm', 'spanmlm']:
-            return self.MLM_tokens(output, target)
-
-
-    def MLM_tokens(self, output, target):
-        B, S, _ = output['input_ids'].shape
-        Loss = []
-        
-        for victim in self.args.mask_list:
-            
-            Loss.append(self.CE_loss(output[victim+'_ids'].view(B*S, -1), 
-                target[victim+'_label'].view(-1).to(output[victim+'_ids'].device)
-                )
-            )
-        
-        return sum(Loss)
-       
-    
-class NoteLoss(BaseLoss):
-    def __init__(self, args):
-        super().__init__(args=args)
-
-        self.args = args
-    def __call__(self):
-        return None
diff --git a/main.py b/main.py
old mode 100644
new mode 100755
index 05ad90a..08131d7
--- a/main.py
+++ b/main.py
@@ -1,110 +1,137 @@
 import argparse
-from ast import Store
+import os, requests
+import sys
 import logging
-import logging.config
 import random
-import os
-import sys
-import glob
+import pprint
+from typing import OrderedDict, Tuple
+from  numbers import Number
+import traceback
 
-from typing import List, Tuple
+import torch.distributed as dist
+import utils.distributed_utils as dist_utils
+import wandb
+
+import numpy as np
+import torch
+from torch.utils.data import DataLoader, DistributedSampler
+from datetime import date
+import torch
 
-# should setup root logger before importing any relevant libraries.
 logging.basicConfig(
     format="%(asctime)s | %(levelname)s %(name)s %(message)s)))",
     datefmt="%Y-%m-%d %H:%M:%S",
     level = os.environ.get("LOGLEVEL", "INFO").upper(),
     stream = sys.stdout
 )
-logger = logging.getLogger(__name__)
+logger = logging.getLogger("train")
 
-import numpy as np
+from utils import utils
+import utils.trainer_utils as trainer_utils
+from loggings import metrics, meters
+from loggings.meters import AverageMeter, StopwatchMeter, TimeMeter
+from datasets.base_dataset import HierarchicalEHRDataset, FlattenEHRDataset, EHRDataset
+import models
+import criterions
 
-import torch
-import torch.multiprocessing as mp
+import signal
+import types
 
 
 def get_parser():
     parser = argparse.ArgumentParser()
-    parser.add_argument(
-        '--device_num', type=str, default='0'
-    )
-
-    # checkpoint configs
-    parser.add_argument('--input_path', type=str, default='/home/edlab/ghhur/Pretrained_DescEmb/data/input')
-    parser.add_argument('--output_path', type=str, default='/home/edlab/ghhur/Pretrained_DescEmb/data/output/')
-    parser.add_argument('--save_dir', type=str, default='checkpoints')
-    parser.add_argument('--save_prefix', type=str, default='checkpoint')
+    parser.add_argument('--input_path', type=str, default='/nfs_edlab/ghhur/UniHPF/input_test2/')
+    #parser.add_argument('--input_path', type=str, default='/home/edlab/jykim/UniHPF_pretrain/input')
+    # parser.add_argument('--input_path', type=str, default='/home/jykim/no_time_filter_data_augment')
+    parser.add_argument('--output_path', type=str, default='/nfs_edlab/ghhur/UniHPF/output')
+    #parser.add_argument('--output_path', type=str, default='/home/edlab/jykim/UniHPF_pretrain/output')
+    # parser.add_argument('--output_path', type=str, default='/home/jykim/UniHPF_pretrain/checkpoints/20220909')
     parser.add_argument('--load_checkpoint', type=str, default=None)
-
-    parser.add_argument('--disable_validation', action='store_true', help='disable validation')
-    parser.add_argument('--disable_save', action='store_true', help='disable save')
+    parser.add_argument('--start_epoch', type=int, default=1)
 
     # dataset
-    parser.add_argument('--train_type', choices=['single', 'transfer', 'pooled'], type=str, default=None)
-    parser.add_argument(
-            '--src_data', 
-            choices=[
-                'mimic3', 
-                'eicu', 
-                'mimic4', 
-                'mimic3_eicu', 
-                'mimic3_mimic4', 
-                'mimic4_eicu', 
-                'mimic3_mimic4_eicu', 
-                'benchmark_mimic', 
-                'benchmark_eicu'
-            ], 
-            type=str, 
-            default='mimic3'
+    parser.add_argument('--pt_src', choices=[
+        'mimiciii', 'eicu', 'mimiciv', 
+        'mimiciii_eicu', 'mimiciii_mimiciv', 'eicu_mimiciv' 
+        'mimiciii_eicu_mimiciv'], type=str, default='mimiciii'
     )
+    
+    parser.add_argument('--train_src', choices=[
+        'mimiciii', 'eicu', 'mimiciv', 
+        'mimiciii_eicu', 'mimiciii_mimiciv', 'eicu_mimiciv' 
+        'mimiciii_eicu_mimiciv'
+        ], type=str, default='mimiciii'
+        )
+    
+    parser.add_argument('--eval_src', choices=[
+        'mimiciii', 'eicu', 'mimiciv', 
+        'mimiciii_eicu', 'mimiciii_mimiciv', 'eicu_mimiciv' 
+        'mimiciii_eicu_mimiciv'
+        ], type=str, default=None
+        )
+    parser.add_argument('--pooled_eval', action='store_true', default=False)
+    parser.add_argument('--pretrain_task',
+        choices=['mlm', 'spanmlm', 'text_encoder_mlm', 'w2v', 'simclr', 'scratch', None], 
+        type=str, 
+        default=None, 
+        help="the pre-training method applied"
+        )
+    
     parser.add_argument('--ratio', choices=['0', '10', '100'], type=str, default='100')
-    parser.add_argument('--feature', choices=['select', 'entire', 'lab_only'], default='whole')
-    parser.add_argument('--eval_data', choices=['mimic3', 'eicu', 'mimic4'], type=str, default=None)
 
+    
+    # parser.add_argument(
+    #     '--pred_tasks',
+    #     default=['mortality', 'long_term_mortality', 'los_3day', 'los_7day', 'readmission', 'final_acuity', 'imminent_discharge', 'diagnosis', 'creatinine', 'bilirubin', 'platelets', 'wbc'],
+    #     choices=['mortality', 'long_term_mortality', 'los_3day', 'los_7day', 'readmission', 'final_acuity', 'imminent_discharge', 'diagnosis', 'creatinine', 'bilirubin', 'platelets', 'wbc'],
+    #     type=list,
+    #     help=""
+    # )
     parser.add_argument(
-        '--pred_target',
-        choices=['mort', 'los3', 'los7', 'readm', 'dx', 'im_disch', 'fi_ac'],
+        '--pred_tasks',
+        default='mortality, long_term_mortality, los_3day, los_7day, readmission, final_acuity, imminent_discharge, diagnosis, creatinine, bilirubin, platelets, wbc',
+        #default='mortality, long_term_mortality, los_3day, los_7day, readmission, final_acuity, imminent_discharge, diagnosis',
+        #default='mortality, long_term_mortality, los_3day, los_7day, readmission, final_acuity, imminent_discharge, diagnosis, creatinine, platelets, wbc',
+        #default='mortality, long_term_mortality, los_3day, los_7day, readmission, diagnosis',
         type=str,
-        default='mort',
         help=""
     )
-
+    
+    
+    parser.add_argument('--emb_type', choices=['codebase', 'textbase'], required=True, type=str, default=None)
+    parser.add_argument('--feature', choices=['select', 'whole'], required=True, type=str, default=None)
+    parser.add_argument('--structure', choices=['hi', 'fl'], required=True, type=str, default=None)
+    
     # trainer
-    parser.add_argument('--train_task', choices=['predict', 'pretrain'], type=str, default=None)
-    parser.add_argument('--seed', type=int, default=2022)
+    parser.add_argument('--train_task', choices=['pretrain', 'sampled_pretrain', 'finetune', 'scratch'], type=str, default=None)
+    parser.add_argument('--seed', type=str, default='42') #TODO: seed args for scratch / finetune in run file
     parser.add_argument('--lr', type=float, default=3e-4)
-    parser.add_argument('--epochs', type=int, default=150)
-    parser.add_argument('--batch_size', type=int, default=128)
-    parser.add_argument('--valid_subsets', type=str, default="valid, test")
-    parser.add_argument('--patience', type=int, default=10)
-    
-    # pretrain
-    parser.add_argument(
-        '--pretrain_task', 
-        choices=['mlm', 'spanmlm', 'cont', 'autore', 'text_encoder_mlm', 'w2v', None], 
-        type=str, default=None
+    parser.add_argument('--max_epoch', type=int, default=300)
+    parser.add_argument('--batch_size', type=int, default=2)
+    parser.add_argument('--valid_subset', type=str, default="valid,test")
+    parser.add_argument('--patience', type=int, default=10) #-> 각 테스크에 따라서 자동 조정
+    parser.add_argument('--criterion', type=str, default=None) #-> 각 테스크에 따라서 자동 조정
+    parser.add_argument( # 'loss' for pretrain, 'auFprc' for finetune #-> 각 테스크에 따라서 자동 조정
+        '--best_checkpoint_metric', type=str, default='loss', choices=['loss', 'auprc', 'acc', 'auroc']
     )
+    parser.add_argument( # 'False' for loss, 'True' for auprc #-> 각 테스크에 따라서 자동 조정
+        '--maximize_best_checkpoint_metric', action='store_true', default=False
+    )
+
+    # pretrain
     parser.add_argument('--mlm_prob', type=float, default=0.15)
-    parser.add_argument('--mask_list', type=str, default='input, type, dpe')
+    parser.add_argument('--mask_list', type=str, default='dpe, input, type')
     
     # model
     parser.add_argument(
-        '--model', choices=['SAnD', 'Rajikomar','DescEmb', 'UniHPF'], type=str, required=True, default='UniHPF',
+        '--model', choices=['ehr_model', 'unihpf_simclr', 'unihpf_w2v', 'unihpf_mlm'], type=str, default='ehr_model',
         help='name of the model to be trained'
     )
-
-    parser.add_argument(
-        '--input2emb_model', type=str, required=False, default=None,
-        choices=['codeemb', 'descemb'], 
-        help='name of the encoder model in the --input2emb_model'
-    )
-    parser.add_arugment('--structure', choices=[None, 'hi', 'fl'] type=str, default=None)
+   
     parser.add_argument(
         '--pred_model', type=str, required=False, default=None,
         help='name of the encoder model in the --pred_model'
     )
-    parser.add_argument('--apply_mean', action='store_true', default=None)
 
     # model hyper-parameter configs
     parser.add_argument('--pred_dim', type=int, default=128)  
@@ -112,14 +139,16 @@ def get_parser():
     parser.add_argument('--n_heads', type=int, default=4)
     parser.add_argument('--n_layers', type=int, default=4)
     parser.add_argument('--dropout', type=float, default=0.2)
-    parser.add_argument('--type_token', action='store_true')
-    parser.add_argument('--dpe', action='store_true')
-    parser.add_argument('--pos_enc', action='store_true')
-    parser.add_argument('--pred_pooling', choices=['cls', 'mean'], default='cls')
+    parser.add_argument('--type_token', action='store_true', default=True)
+    parser.add_argument('--dpe', action='store_true', default=True)
+    parser.add_argument('--pos_enc', action='store_true', default=True)
+    parser.add_argument('--pred_pooling', choices=['cls', 'mean'], default='mean')
     parser.add_argument('--text_post_proj', action='store_true')
     parser.add_argument('--map_layers', type=int, default=1)
-    parser.add_argument('--max_word_len', type=int, default=256)
+    parser.add_argument('--max_word_len', type=int, default=128)
     parser.add_argument('--max_seq_len', type=int, default=8192)
+    parser.add_argument('--time_embed', type=str, choices=[None, 'Timegap', 'Alibi'], default=None)
+
 
     # for w2v
     parser.add_argument('--feature_grad_mult', type=float, default=0.1)
@@ -139,166 +168,668 @@ def get_parser():
     parser.add_argument('--mask_other', type=float, default=0)
     parser.add_argument('--no_mask_overlap', type=bool, default=False)
     parser.add_argument('--mask_min_space', type=int, default=0)
-
+    parser.add_argument('--perp_weight', type=float, default=0.1)
+    parser.add_argument('--reg_weight', type=int, default=5)
+    parser.add_argument(
+        '--log_interval', type=int, default=10,
+    )
 
     # for ddp setting
-    parser.add_argument('--DDP', action='store_true') # Temporal argument should be removed
     parser.add_argument('--dp', action='store_true')
     parser.add_argument('--world_size', type=int, default=1)
     parser.add_argument('--port', type=str, default = '12355')
-
-
-    parser.add_argument('--debug', action='store_true')
     
-    # MLM pretrained load
-    parser.add_argument('--pretrained_path', type=str)
-    parser.add_argument('--pretrained_load', type=str, 
-        choices=[None, 'mlm', 'spanmlm', 'w2v'], default=None)
-
+   
     # resume
+    parser.add_argument('--pretrained_path', type=str, default=None)
     parser.add_argument('--resume', action='store_true')
 
+    parser.add_argument('--edlab_resume', action='store_true')
+
+    parser.add_argument(
+        '--wandb', action='store_true', default=False,
+    )
+    parser.add_argument(
+        '--wandb_project_name', type=str, default=None
+    )
+    parser.add_argument(
+        '--wandb_entity', type=str, default='hoon9405'
+    )
+    parser.add_argument(
+        '--wandb_run_name', type=str, default=None
+    )
+    parser.add_argument(
+         '--sub_id', type=str, default=None
+     )
+
+    # nsml
+    parser.add_argument( # True when using nsml
+        '--auto_resume', action='store_true', default=False,
+    ) 
+    parser.add_argument( # resume directory
+        '--resume_path', type=str, default=None
+    )
+
     return parser
 
-def main():
-    args = get_parser().parse_args()
-   
-    #parsing args
-    args.valid_subsets = (
-        args.valid_subsets.replace(' ','').split(',')
-        if (
-            not args.disable_validation
-            and args.valid_subsets
-            and bool(args.valid_subsets.strip())
+
+def sigterm_handler(s: signal.Signals, f: types.FrameType) -> None:
+    raise KeyboardInterrupt
+
+
+def load_dataset(args, split, dataname, seed) -> None:
+    if args.structure =='hi':
+        ds = HierarchicalEHRDataset(
+            data=dataname,
+            emb_type=args.emb_type,
+            feature=args.feature,
+            input_path=args.input_path,
+            split=split,
+            structure=args.structure,
+            train_task=args.train_task,
+            ratio=args.ratio,
+            pred_tasks=args.pred_tasks,
+            seed=args.seed,
+            mask_list=args.mask_list,
+            pretrain_task=args.pretrain_task,
+            mlm_prob=args.mlm_prob,
+            max_word_len=args.max_word_len,
+            max_seq_len=args.max_seq_len,
+        )
+    elif args.structure=='fl':
+        ds = FlattenEHRDataset(
+            data=dataname,
+            emb_type=args.emb_type,
+            feature=args.feature,
+            input_path=args.input_path,
+            split=split,
+            structure=args.structure,
+            train_task=args.train_task,
+            ratio=args.ratio,
+            pred_tasks=args.pred_tasks,
+            seed=args.seed,
+            mask_list=args.mask_list,
+            pretrain_task=args.pretrain_task,
+            mlm_prob=args.mlm_prob,
+            max_word_len=args.max_word_len,
+            max_seq_len=args.max_seq_len,
         )
-        else []
+    
+    return ds
+
+def load_dataloader(dataset, batch_size, seed, collator) -> None:
+    sampler = None if not dist.is_initialized() else (
+    DistributedSampler(dataset, seed=seed)
     )
-   
-    args.mask_list = (
-        args.mask_list.replace(' ','').split(',')
+    dataloader = DataLoader(
+        dataset,
+        batch_size=batch_size,
+        shuffle=True if not dist.is_initialized() else False,
+        num_workers=0,
+        collate_fn=collator,
+        sampler=sampler,
+    )  
+ 
+    return dataloader, sampler
+
+
+def pre_main(args):
+    args.pred_tasks = [item.strip() for item in args.pred_tasks.split(',')]
+    
+    if args.valid_subset and len(args.valid_subset) > 0:
+        args.valid_subset = args.valid_subset.replace(' ','').split(',')
+
+    if args.mask_list and len(args.mask_list) > 0:
+        args.mask_list = args.mask_list.replace(' ','').split(',')
+
+    if args.seed and len(args.seed) > 0:
+        args.seed = [int(s) for s in args.seed.replace(' ','').split(',')]
+
+
+    #single prediction
+    if len(args.pred_tasks)>1:
+        args.single_pred = False
+        args.pred_task_save='all'
+    else:
+        args.single_pred = True
+        args.pred_task_save=args.pred_tasks
+
+
+    if args.train_task in ['scratch', 'finetune']: #TODO: check 명령어 for finetune / pretrain
+        assert len(args.seed) == 1, "Scratch / Finetune should run on one seed"
+    elif 'pretrain' in args.train_task:
+        assert len(args.seed) == 5, "Pretrain should run on 5 seeds"
+        assert len(args.valid_subset) == 0, "Pretrain should not have valid subset"
+
+
+    if 'pretrain' in args.train_task:
+        args.checkpoint_prefix = f'{args.pretrain_task}_train_{args.train_src}_{args.time_embed}_{args.pred_task_save}_{args.seed[0]}'
+    elif args.train_task == 'finetune':
+        args.checkpoint_prefix = f'pt_{args.pt_src}_{args.ratio}_{args.pretrain_task}_train_{args.train_src}_{args.time_embed}_{args.pred_task_save}_{args.seed[0]}'
+    elif args.train_task == 'scratch':
+        args.checkpoint_prefix = f'scratch_train_{args.train_src}_{args.time_embed}_{args.pred_task_save}_{args.seed[0]}'
+
+
+    if args.auto_resume:
+        args.resume = False
+        os.makedirs(args.resume_path, exist_ok=True)
+        prev_exps = os.listdir(args.resume_path)
+
+        for i in prev_exps:
+            if i == f'{args.checkpoint_prefix}checkpoint_last.pt':
+                args.resume = True
+                logger.info(f"Resume checkpoint from {i}")
+                break
+    
+    args.checkpoint_save_path = os.path.join(args.output_path, args.train_task, f'{args.emb_type}_{args.feature}_{args.structure}')
+    os.makedirs(args.checkpoint_save_path, exist_ok=True)
+
+    args.log_prefix=f'{args.train_task}_{args.pretrain_task}_{args.emb_type}_{args.structure}'
+
+    #wandb setting
+    if args.wandb_project_name is None:
+        args.wandb_project_name = args.log_prefix
+    if args.wandb_run_name is None:
+        args.wandb_run_name = args.checkpoint_prefix
+
+    dist_utils.call_main(args, main)
+
+
+def model_load(path):
+    state_dict = torch.load(path, map_location='cpu')
+    model = state_dict['model']
+    epoch = state_dict['epoch']
+    optimizer = state_dict['optimizer']
+    valid_losses = state_dict['valid_losses']
+    try:
+        num_runs = state_dict['patience']
+    except KeyError:
+        num_runs = 0
+
+    return model, epoch, optimizer, num_runs, valid_losses
+
+
+def main(args) -> None:
+    signal.signal(signal.SIGTERM, sigterm_handler)
+    np.random.seed(args.seed[0])
+    random.seed(args.seed[0])
+    utils.set_torch_seed(args.seed[0])
+
+    args.pred_tasks = [trainer_utils.get_task(task, args.train_src) for task in args.pred_tasks]
+    
+    logger.info(pprint.pformat(args))
+
+
+    # model & criterion build
+    model = models.build_model(args)
+    
+    # resume
+    if args.load_checkpoint is not None:     
+        model = model.from_pretrained(args, checkpoint=args.load_checkpoint)
+        print("Model training from args checkpoint "+ args.load_checkpoint + " ...")
+        
+    elif (args.auto_resume and args.resume) or args.edlab_resume:
+        if args.auto_resume and args.resume:
+            ckpt_load_path = os.path.join(args.resume_path, f'{args.checkpoint_prefix}checkpoint_last.pt')
+        elif args.edlab_resume:
+            ckpt_load_path = os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}checkpoint_last.pt')
+        
+        model_loaded, args.start_epoch, optimizer, num_runs, valid_losses = model_load(ckpt_load_path)
+        utils.should_stop_early.num_runs = num_runs
+        utils.should_stop_early.best = valid_losses[0]
+                
+        model = model.from_pretrained(args, state_dict=model_loaded) 
+        
+        print("Resume training from checkpoint "+ ckpt_load_path + " ...")
+    
+    elif args.train_task =='finetune':    
+        pretrain_prefix = 'scratch' if args.pretrain_task =='scratch' else 'pretrain'
+        pt_ckpt_save_dir = os.path.join(args.output_path, pretrain_prefix, f'{args.emb_type}_{args.feature}_{args.structure}')
+        pt_ckpt_name = f'{args.pretrain_task}_train_{args.pt_src}_{args.time_embed}_{args.pred_task_save}_{args.seed[0]}'
+        ckpt_load_path = os.path.join(pt_ckpt_save_dir, f'{pt_ckpt_name}_{args.pt_src}_checkpoint_best.pt')
+        model = model.from_pretrained(args, checkpoint=ckpt_load_path)
+        print("Finetune- Loaded checkpoint from "+ ckpt_load_path + " ...")
+    
+    criterion = criterions.build_criterion(args)
+    
+    logger.info(model)
+    logger.info('model: {}'.format(model.__class__.__name__))
+    logger.info(
+        'num. shared model params: {:,} (num. trained: {:,})'.format(
+            sum(p.numel() for p in model.parameters()),
+            sum(p.numel() for p in model.parameters() if p.requires_grad)
+        )
+    )
+    
+    #dataloader build
+    if args.eval_src is None:
+        args.eval_src = (
+            args.train_src.split('_')
+        )
+        if args.pooled_eval:
+            args.eval_src += [args.train_src]
+    
+    
+    if args.valid_subset and len(args.valid_subset) > 0:
+        data_split = ['train'] + args.valid_subset
+    else:
+        print("Only in train mode (no evaluation)")
+        data_split = ['train']
+        
+    datanames = [args.train_src] + args.eval_src*len(args.valid_subset)
+        
+    dataloaders = {k:{} for k in data_split}
+    samplers = {k:{} for k in data_split}
+        
+    for split in data_split:
+        if split=='train':
+            datanames = [args.train_src]
+        else:
+            datanames = args.eval_src
+                        
+        for dataname in datanames:
+            for data in dataname.split('_'):
+                concat_list = [] 
+                dataset= load_dataset(args, split, data, args.seed)
+                concat_list.append(dataset)
+                logger.info(f'{split}, {len(dataset)}')
+
+            dataloader, sampler = load_dataloader(
+                torch.utils.data.ConcatDataset(concat_list), 
+                args.batch_size, 
+                args.seed[0], 
+                concat_list[0].collator
+                )
+            dataloaders[split].update({dataname: dataloader})
+            samplers[split].update({dataname: sampler})
+        
+    logger.info(f'{args.train_task}, {data_split}, {dataloaders}')
+  
+    # trainer build
+    from trainers.base_trainer import BaseTrainer as Trainer
+
+    trainer = Trainer(args, model, criterion)
+
+    logger.info(
+        'training on {} devices (GPUs)'.format(
+            args.world_size
+        )
     )
 
-    if args.train_type =='pooled':
-        if args.train_task =='predict':
-            args.eval_data = ([args.src_data] + 
-                    args.src_data.split('_')
-                )  
+    max_epoch = args.max_epoch
+    lr = args.lr
+    
+    if args.wandb and dist_utils.is_master(args): # TODO: need update for automatic resume
+        if (args.resume or args.edlab_resume) and (args.sub_id is not None):
+            wandb.init(
+                project=args.wandb_project_name,
+                entity=args.wandb_entity,
+                config=args,
+                id=args.wandb_run_name + '-' + args.sub_id,
+                resume="must"
+            )
+        else:
+            args.sub_id = wandb.util.generate_id()
+            wandb.init(
+                project=args.wandb_project_name,
+                entity=args.wandb_entity,
+                config=args,
+                id=args.wandb_run_name + '-' + args.sub_id,
+                reinit=True
+            )
+
+        wandb.run_name = args.wandb_run_name
+
+    cum_data_count = 0
+
+    train_meter = meters.StopwatchMeter()
+    train_meter.start()
+
+    #train
+    try:
+        if (args.auto_resume and args.resume) or args.edlab_resume:
+            print("Start patience: ", utils.should_stop_early.num_runs)
+        
+        for i in range(args.start_epoch, max_epoch + 1):
+            
+            cum_data_count += len(dataloaders['train'][args.train_src])
+            validation = True if 'valid' in data_split else False
+            valid_losses, should_stop = train(args, trainer, cum_data_count, epoch_itr=dataloaders, epoch=i, sampler=samplers, validation=validation)
+            if should_stop:
+                break
+        # TODO -test 
+        if 'test' in args.valid_subset:
+            for dataname in dataloaders['test'].keys():
+                best_state_dict = torch.load(os.path.join(
+                    args.checkpoint_save_path, f'{args.checkpoint_prefix}_{dataname}_checkpoint_best.pt'), map_location='cpu'
+                    )['model']
+                if not isinstance(trainer.model, torch.nn.parallel.DistributedDataParallel):
+                    trainer.model.load_state_dict(best_state_dict, strict=True) # load best ckpt for testing
+                else:
+                    trainer.model.module.load_state_dict(best_state_dict, strict=True)
+                print(f"{dataname} loaded best checkpoint")
+                
+                valid_losses = validate(args, trainer, dataloaders, 'test', dataname)
+                logger.info(f'test_losses = {valid_losses}')
+
+            train_meter.stop()
+
+        if args.wandb and dist_utils.is_master(args):
+            wandb.finish(0)
+        logger.info('done training in {:.1f} seconds'.format(train_meter.sum))
+
+    except KeyboardInterrupt: # when sigterm in nsml -> save last checkpoint and reschedule
+        if args.auto_resume and dist_utils.is_master(args):
+
+            print("INTERRUPTED!!")
+
+            resume_state_dict = torch.load(os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}checkpoint_last.pt'), map_location='cpu')
+
+            os.makedirs(args.resume_path, exist_ok=True)
+
+            torch.save(
+                resume_state_dict,
+                os.path.join(args.resume_path, f'{args.checkpoint_prefix}checkpoint_last.pt')
+            )
+
+            # logger.info("Finish saving before interrupt")
+            print("Finish saving before interrupt")
+
+            try:
+                api_host = os.environ["NSML_RUN_METADATA_API"]
+                api_secret = os.environ["NSML_RUN_SECRET"]
+                requests.put(
+                    f"{api_host}/v1/rescheduled",
+                    headers={"X-NSML-Run-Secret": api_secret},
+                    json={"rescheduled": True},
+                ).raise_for_status()
+                print("send rescheduling request")
+            except:
+                # Sometimes, the HTTP request might fail, but the training process should not be stopped.
+                traceback.print_exc()
+
+        else:
+            print("[KeyboardInterrupt] Not run in auto-resume mode")
+        if args.wandb:
+            wandb.finish()
+
+
+@metrics.aggregate('train')
+def train(args, trainer, cum_data_count, epoch_itr, epoch, sampler, validation):
+    logger.info('begin training epoch {}'.format(epoch))
+
+    if dist.is_initialized():
+        sampler['train'][args.train_src].set_epoch(epoch)
+
+    should_stop = False
+    num_updates = trainer.get_num_updates()
+    logger.info('Start iterating over samples')
+    logger.info(f'len(epoch_itr[train]) ={len(epoch_itr["train"][args.train_src])}')
+    
+    for i, sample in enumerate(epoch_itr['train'][args.train_src]):
+        logger.info('train_inner')
+        logger.info(f'i ={i}')
+        # if i == 3:
+        #     sample['labels']['bilirubin'] = torch.tensor([-100]*16, dtype=torch.int64)
+        # if sample['labels']['bilirubin'].sum() == -1600:
+        #     logger.info(f"{sample['labels']['bilirubin']}")
+        #     breakpoint()
+        with metrics.aggregate('train_inner'):
+            log_output = trainer.train_step(sample)
+        logger.info('finish train inner')
+        if log_output is not None:
+            num_updates = trainer.get_num_updates()
+            if num_updates % args.log_interval == 0:
+                stats = get_training_stats(metrics.get_smoothed_values('train_inner'))
+                progress_log(
+                    args,
+                    stats, 
+                    tag='train_inner', 
+                    step=num_updates, 
+                    size=cum_data_count, 
+                    log_wandb=args.wandb
+                    )
+                # print(metrics.state_dict()['train_inner'])
+                metrics.reset_meters('train_inner')
+    
+    stats = get_training_stats(metrics.get_smoothed_values('train'))
+    logger.info('finish get training stasts inner')
+    progress_print(args, stats, tag='train', log_wandb=args.wandb)
+
+    if validation:
+        logger.info('Evaluation start') 
+        stop_list = []   
+        for dataname in epoch_itr['valid'].keys():
+            valid_losses, should_stop = validate_and_save(args, trainer, epoch_itr, epoch, 'valid', dataname)
+            if should_stop:
+                stop_list.append(dataname)
+        
+        if len(stop_list)>0:
+            for stop_data in stop_list:
+                del epoch_itr['valid'][stop_data]
+                
+        if len(epoch_itr['valid'])==0:
+            should_stop = True
         else:
-            args.eval_data = [args.src_data] 
-    elif args.train_type=='single':
-        args.eval_data = [args.src_data]
+            should_stop = False
+            # 여기 should stop을 기준으로 dataloaders 에서 삭제
     else:
-        args.eval_data= [args.eval_data]
+        valid_losses, should_stop = validate_and_save(args, trainer, epoch_itr, epoch, 'train', args.train_src)
+    logger.info('end of epoch {} (average epoch stats below)'.format(epoch))
+        
+    metrics.reset_meters('train')
+    return valid_losses, should_stop
+
+# def train_save(args, trainer, epoch, stats, dataname):
+#     should_stop = False
+
+#     valid_losses = []
+#     stats = get_train_stats(args, stats)
+#     valid_losses.append(stats[f'{dataname}_{args.best_checkpoint_metric}'])
+#     logger.info(f'train_losses = {valid_losses}')
+#     should_stop |= utils.should_stop_early(
+#         args.patience,
+#         dataname,
+#         valid_losses[0],
+#         descending=(not args.maximize_best_checkpoint_metric)
+#     )
+
+#     state_dict = {
+#         'model': trainer.model.state_dict() if not (
+#             isinstance(trainer.model, torch.nn.parallel.DistributedDataParallel)
+#         ) else trainer.model.module.state_dict(),
+#         'epoch': epoch,
+#         'optimizer': trainer.optimizer.state_dict(),
+#         'valid_losses': valid_losses,
+#         'patience': utils.should_stop_early.num_runs[dataname],
+#     }
+
+#     if 'pretrain' in args.train_task:
+#         torch.save(
+#             state_dict,
+#             os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_checkpoint_last.pt')
+#         )
+
+#         if utils.should_stop_early.best[dataname] == valid_losses[0]:
+#             torch.save(
+#                 state_dict,
+#                 os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_{dataname}_checkpoint_best.pt')
+#             )
+
+#     torch.save(
+#         state_dict,
+#         os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_checkpoint_last.pt')
+#     )
+
+#     if utils.should_stop_early.best[dataname] == valid_losses[0]:
+#         torch.save(
+#             state_dict,
+#             os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_{dataname}_checkpoint_best.pt')
+#         )
+    
+#     return valid_losses, should_stop
+
+def validate_and_save(args, trainer, epoch_itr, epoch, valid_subset, dataname):
+    num_updates = trainer.get_num_updates()
+    should_stop = False
+    training_time_hours = trainer.cumulative_training_time() / (60 * 60)
+
+    valid_losses = validate(args, trainer, epoch_itr, valid_subset, dataname)
+    logger.info(f'valid_losses = {valid_losses}')
+    should_stop |= utils.should_stop_early(
+        args.patience,
+        dataname,
+        valid_losses[0],
+        descending=(not args.maximize_best_checkpoint_metric)
+    )
 
-    model_configs = {
-    'SAnD': ('fl', 'codeemb', 'select'), 
-    'Rajikomar' : ('hi', 'codeemb', 'entire'),
-    'DescEmb' : ('hi', 'descemb', 'select') 
-    'UniHPF': ('hi', 'descemb', 'entire')  
+    state_dict = {
+        'model': trainer.model.state_dict() if not (
+            isinstance(trainer.model, torch.nn.parallel.DistributedDataParallel)
+        ) else trainer.model.module.state_dict(),
+        'epoch': epoch,
+        'optimizer': trainer.optimizer.state_dict(),
+        'valid_losses': valid_losses,
+        'patience': utils.should_stop_early.num_runs[dataname] ,
     }
 
-    structure, input2emb, feature = model_configs[args.model]
+    if 'pretrain' in args.train_task:
+        torch.save(
+            state_dict,
+            os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_checkpoint_last.pt')
+        )
 
-    if args.structure is None:
-        args.structrue = structure
-    if args.input2emb is None:
-        args.input2emb = input2emb
-    if args.feature is None:
-        args.feature = feature
+        if utils.should_stop_early.best[dataname] == valid_losses[0]:
+            torch.save(
+                state_dict,
+                os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_{dataname}_checkpoint_best.pt')
+            )
 
-    if args.train_type =='single' and len(args.eval_data)!=1:
-        raise AssertionError('single domain training must select single dataset')
+    torch.save(
+        state_dict,
+        os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_checkpoint_last.pt')
+    )
 
-    if args.train_type =='pooled' and args.src_data in ['mimic3', 'eicu', 'mimic4']:
-        raise AssertionError('pooled must select at least two datasets')
+    if utils.should_stop_early.best[dataname] == valid_losses[0]:
+        torch.save(
+            state_dict,
+            os.path.join(args.checkpoint_save_path, f'{args.checkpoint_prefix}_{dataname}_checkpoint_best.pt')
+        )
     
-    if args.train_type =='transfer' and (args.eval_data[0] in args.src_data):
-        raise AssertionError('transfer target should not be in trained src data')
+    return valid_losses, should_stop
+
+def get_training_stats(stats):
+    stats['wall'] = round(metrics.get_meter('default', 'wall').elapsed_time, 0)
+    return stats
+
+def validate(args, trainer, epoch_itr, valid_subset, dataname):
+    valid_losses = []
+    # for subset in args.valid_subset:
+    logger.info('begin validation on "{}" subset, data {}'.format(valid_subset, dataname))
 
-    if args.train_task =='pretrain' and args.pretrain_task is None:
-        raise AssertionError('should select pretrain task')
+    with metrics.aggregate(new_root=True) as agg:
+        for i, sample in enumerate(epoch_itr[valid_subset][dataname]):
+            trainer.valid_step(sample, subset=valid_subset, dataname=dataname)
 
+    stats = get_valid_stats(args, trainer, valid_subset, dataname, agg.get_smoothed_values())
+
+    progress_print(args, stats, tag=valid_subset, prefix=f'valid on {valid_subset} subset, data {dataname}', log_wandb=args.wandb)
+    valid_losses.append(stats[f'{dataname}_{args.best_checkpoint_metric}'])
    
-    os.environ["CUDA_VISIBLE_DEVICES"] = str(args.device_num)
-
-    args.device_ids = list(range(len(args.device_num.split(','))))
-    print('device_number : ', args.device_ids)
-    args.world_size = len(args.device_ids)
-    ckpt_root = set_struct(vars(args))
-
-    #seed pivotting
-    mp.set_sharing_strategy('file_system')
-    random.seed(seed)
-    np.random.seed(seed)
-    torch.manual_seed(seed)
-    torch.cuda.manual_seed(seed)
-    torch.cuda.manual_seed_all(seed)  # if use multi-GPU
-    torch.backends.cudnn.deterministic = True
-        
-    if args.train_task == 'predict':
-        from trainers import BaseTrainer as Trainer
-    elif args.train_task == 'pretrain' and args.pretrain_task == 'w2v':
-        from trainers import W2VTrainer as Trainer
-    elif args.train_task == 'pretrain' and args.pretrain_task == 'mlm'::
-        from trainers import MLMTranier as Trainer
-    else:
-        raise NotImplementedError("Need proper trainer")
+    return valid_losses
 
-    trainer=Trainer(args, seed)
-    trainer.train()
-    logger.info("done training")
+def get_valid_stats(args, trainer, subset, dataname, stats):
+    stats['num_updates'] = trainer.get_num_updates()
 
-def set_struct(cfg: dict):
-    root = os.path.abspath(
-        os.path.dirname(__file__)
+    if not hasattr(get_valid_stats, 'best'):
+        get_valid_stats.best = dict()
+    
+    prev_best = getattr(get_valid_stats, 'best').get(
+        subset, stats[f'{dataname}_{args.best_checkpoint_metric}']
     )
-    from datetime import datetime
-    now = datetime.now()
-    from pytz import timezone
-    # apply timezone manually
-    now = now.astimezone(timezone('Asia/Seoul'))
-
-    output_dir = os.path.join(
-        root,
-        "outputs",
-        now.strftime("%Y-%m-%d"),
-        now.strftime("%H-%M-%S")
+    best_function = max if args.maximize_best_checkpoint_metric else min
+    get_valid_stats.best[subset] = best_function(
+        stats[f'{dataname}_{args.best_checkpoint_metric}'], prev_best
     )
 
-    if not os.path.exists(output_dir):
-        os.makedirs(output_dir)
-
-    os.chdir(output_dir)
-
-    job_logging_cfg = {
-        'version': 1,
-        'formatters': {
-            'simple': {
-                'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
-            }
-        },
-        'handlers': {
-            'console': {
-                'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'
-            },
-            'file': {
-                'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'train.log'
-            }
-        },
-        'root': {
-            'level': 'INFO', 'handlers': ['console', 'file']
-            },
-        'disable_existing_loggers': False
-    }
-    logging.config.dictConfig(job_logging_cfg)
+    key = 'best_{0}'.format(f'{dataname}_{args.best_checkpoint_metric}')
+    stats[key] = get_valid_stats.best[subset]
+
+    return stats
+
+def get_train_stats(args, stats, dataname):
+
+    if not hasattr(get_train_stats, 'best'):
+        get_train_stats.best = dict()
+    
+    prev_best = getattr(get_train_stats, 'best').get(
+        'train', stats[f'{dataname}_{args.best_checkpoint_metric}']
+    )
+    best_function = max if args.maximize_best_checkpoint_metric else min
+    get_train_stats.best['train'] = best_function( # epsilon
+        stats[f'{dataname}_{args.best_checkpoint_metric}'], prev_best
+    )
 
-    cfg_dir = ".config"
-    os.mkdir(cfg_dir)
-    os.mkdir(cfg['save_dir'])
+    key = 'best_{0}'.format(f'{dataname}_{args.best_checkpoint_metric}')
+    stats[key] = get_train_stats.best['train']
+
+    return stats
+
+
+def format_stat(stat):
+    if isinstance(stat, Number):
+        stat = "{:g}".format(stat)
+    elif isinstance(stat, AverageMeter):
+        stat = "{:.3f}".format(stat.avg)
+    elif isinstance(stat, TimeMeter):
+        stat = "{:g}".format(round(stat.avg))
+    elif isinstance(stat, StopwatchMeter):
+        stat = "{:g}".format(round(stat.sum))
+    elif torch.is_tensor(stat):
+        stat = stat.tolist()
+    return stat
+
+
+def _format_stats(stats):
+    postfix = OrderedDict(stats)
+    # Preprocess stats according to datatype
+    for key in postfix.keys():
+        postfix[key] = str(format_stat(postfix[key]))
+    return postfix
+
+def _str_pipes(stats):
+    return ' | '.join(key + ' ' + stats[key].strip() for key in stats.keys())
+
+def _str_commas(stats):
+    return ', '.join(key + '=' + stats[key].strip() for key in stats.keys())
+
+def progress_log(args, stats, tag=None, step=0, size=1, prefix='', log_wandb=False):
+    stats = _format_stats(stats)
+    postfix = _str_commas(stats)
+    with utils.rename_logger(logger, tag):
+        logger.info(
+            '{}: {:5d} / {:d} {}'.format(
+                prefix, step, size, postfix
+            )
+        )
+        if log_wandb and dist_utils.is_master(args):
+            _stats = {}
+            for key in stats:
+                _stats[tag + '/' + key] = float(stats[key])
+            wandb.log(_stats)
+
+def progress_print(args, stats, tag=None, prefix='', log_wandb=False):
+    postfix = _str_pipes(_format_stats(stats))
+    with utils.rename_logger(logger, tag):
+        logger.info('{} | {}'.format(prefix, postfix))
+        if log_wandb and dist_utils.is_master(args):
+            _stats = {}
+            for key in stats:
+                _stats[tag + '/' + key] = float(stats[key])
+            wandb.log(_stats)
 
-    with open(os.path.join(cfg_dir, "config.yaml"), "w") as f:
-        for k, v in cfg.items():
-            print("{}: {}".format(k, v), file=f)
 
 if __name__ == '__main__':
-    main()
+    parser = get_parser()
+    args = parser.parse_args()
+    pre_main(args)
diff --git a/metrics/__init__.py b/metrics/__init__.py
deleted file mode 100644
index bf71313..0000000
--- a/metrics/__init__.py
+++ /dev/null
@@ -1,13 +0,0 @@
-from .metric import (
-    BaseMetric,
-    PredMetric,
-    PretrainMetric,
-    #NoteMetric
-)
-
-__all__ = [
-    BaseMetric,
-    PredMetric,
-    PretrainMetric,
-    #NoteMetric
-]
\ No newline at end of file
diff --git a/metrics/metric.py b/metrics/metric.py
deleted file mode 100644
index cc8b226..0000000
--- a/metrics/metric.py
+++ /dev/null
@@ -1,220 +0,0 @@
-from builtins import setattr
-from numpy import argmax
-from sklearn.metrics import average_precision_score, roc_auc_score
-from sklearn.preprocessing import MultiLabelBinarizer
-import torch
-import numpy as np
-
-class BaseMetric(object):
-    def __init__(self): 
-        pass
-
-    @property
-    def compare(self):
-        raise NotImplementedError
-
-    def reset(self):
-        raise NotImplementedError
-    
-    def __call__(self):
-        raise NotImplementedError
-
-class PredMetric(BaseMetric):
-    def __init__(self, args, target='auprc'):
-        self._update_target = target
-        self.reset()
-        
-        self.pred_target = args.pred_target
-
-        self.multi_label_dict = {
-            'mimic3':{
-                'dx':18,
-                'im_disch':17,
-                'fi_ac':18},
-            'eicu':{
-                'dx':18,
-                'im_disch':8,
-                'fi_ac':9},
-             'mimic4':{
-                'dx':18,
-                'im_disch':17,
-                'fi_ac':18},
-        }
-        
-
-        self.mlb = None
-        if args.pred_target in ['fi_ac', 'im_disch']:
-            self.mlb = MultiLabelBinarizer()
-            class_n = self.multi_label_dict[args.src_data][args.pred_target]
-            self.mlb.fit([[i] for i in range(class_n)])
-
-    def reset(self):
-        self.loss = 0
-        self.truths = []
-        self.preds = []
-
-    def __call__(self, loss: float, preds: np.ndarray, truths: np.ndarray, **kwargs):
-        self.truths += list(truths)
-        self.preds += list(preds)
-        self.loss += loss
-
-    def get_epoch_dict(self, total_iter):
-        self.epoch_dict = {
-            'auroc' : self.auroc,
-            'auprc' : self.auprc,
-            'loss' :  self.loss / total_iter
-            }
-        self.reset()
-
-        return self.epoch_dict
-
-    @property
-    def compare(self):
-        return 'decrease' if self.update_target == 'loss' else 'increase'
-
-    @property
-    def update_target(self):
-        return self._update_target
-
-    @property
-    def auroc(self):
-        if self.mlb:
-            self.truths = self.mlb.transform(
-            np.expand_dims(np.array(self.truths, dtype='int'), axis=1)).flatten()
-        return roc_auc_score(self.truths, self.preds)
-
-    @property
-    def auprc(self):
-        return average_precision_score(self.truths, self.preds, average='micro')
-
-class PretrainMetric(BaseMetric):
-    def __init__(self, args, target=None):
-        self.mask_list = args.mask_list
-        self.reset()
-    
-    def reset(self):
-        self.loss = 0
-        self.total = {
-            victim+'_ids': 0 for victim in self.mask_list
-        }
-        self.correct = {
-            victim+'_ids': 0 for victim in self.mask_list
-        }
-
-    def __call__(self, loss, total, correct):
-        self.loss += loss
-        for victim in self.mask_list:
-            self.total[victim+'_ids'] += total[victim+'_ids']
-        for victim in self.mask_list:
-            self.correct[victim+'_ids'] += correct[victim+'_ids']
-
-    def get_epoch_dict(self, total_iter):
-        log_dict = {'Loss': self.loss / total_iter}
-        for victim in self.mask_list:
-            log_dict[victim+'_ids_acc'] = self.correct[victim+'_ids'] / self.total[victim+'_ids']
-        self.reset()
-
-        return log_dict
-
-    @property
-    def compare(self):
-        return 'decrease' if self.update_target == 'loss' else 'increase'
-
-    @property
-    def update_target(self):
-        return 'input_ids_acc'
-
-class W2VMetric(BaseMetric):
-    def __init__(self, target='acc'):
-        self._update_target = target
-        self.reset()
-    
-    def reset(self):
-        self.loss_0 = 0
-        self.loss_1 = 0
-        self.loss_2 = 0
-        self.prob_ppl = 0
-        self.code_ppl = 0
-        self.total = 0
-        self.correct = 0
-
-    def update(
-        self,
-        loss_0=0,
-        loss_1=0,
-        loss_2=0,
-        total=0,
-        correct=0,
-        prob_ppl=0,
-        code_ppl=0,
-    ):
-        self.loss_0 += loss_0
-        self.loss_1 += loss_1
-        self.loss_2 += loss_2
-        
-        self.prob_ppl += prob_ppl
-        self.code_ppl += code_ppl
-        self.total += total
-        self.correct += correct
-    
-    def get_epoch_dict(self, total_iter):
-        epoch_dict = {
-            'loss': (self.loss_0 + self.loss_1 + self.loss_2) / total_iter,
-            'loss_0': self.loss_0 / total_iter,
-            'loss_1': self.loss_1 / total_iter,
-            'loss_2': self.loss_2 / total_iter,
-            'prob_ppl': self.prob_ppl / total_iter,
-            'code_ppl': self.code_ppl / total_iter,
-            'acc': self.acc
-        }
-        self.reset()
-    
-        return epoch_dict
-    
-    @property
-    def compare(self):
-        return 'decrease' if self.update_target == 'loss' else 'increase'
-    
-    @property
-    def update_target(self):
-        return self._update_target
-    
-    @property
-    def acc(self):
-        return self.correct / self.total if self.total > 0 else float("nan")
-
-class NoteMetric(BaseMetric):
-    def __init__(self, target='acc'):
-        self._update_target = target
-        self.reset()
-
-    def reset(self):
-        self.loss = 0
-        self.total = 0
-        self.correct = 0
-
-    def update(self, loss, total, correct):
-        self.loss += loss
-        self.total += total
-        self.correct += correct
-
-    def get_epoch_dict(self, total_iter):
-        epoch_dict = {
-            'loss': self.loss / total_iter,
-            'acc': self.acc
-        }
-        self.reset()
-       
-        return epoch_dict
-
-    @property
-    def compare(self):
-        return 'decrease' if self.update_target == 'loss' else 'increase'
-    
-    @property
-    def update_target(self):
-        return self._update_target
-    
-    @property
-    def acc(self):
-        return self.correct / self.total if self.total > 0 else float("nan")
diff --git a/models/__init__.py b/models/__init__.py
old mode 100644
new mode 100755
index 6f38dd5..19bfdc9
--- a/models/__init__.py
+++ b/models/__init__.py
@@ -25,12 +25,6 @@ def register_model(name):
     New model types can be added with the :func:`register_model`
     function decorator.
 
-    For example:
-
-        @register_model('descemb_bert')
-        class BertTextEncoder(nn.Module):
-            (...)
-
     Args:
         name (str): the name of the model
     """
diff --git a/models/base_model.py b/models/base_model.py
deleted file mode 100644
index 2b7946a..0000000
--- a/models/base_model.py
+++ /dev/null
@@ -1,67 +0,0 @@
-import os
-import logging
-
-import torch
-from torch._C import Value
-import torch.nn as nn
-
-from models import register_model, MODEL_REGISTRY
-
-logger = logging.getLogger(__name__)
-
-@register_model("base_model")
-class BaseModel(nn.Module):
-    def __init__(self, args):
-        super().__init__()
-        self.args = args
-
-        self.input2emb_model = self._input2emb_model.build_model(args)
-        self.pred_model = self._pred_model.build_model(args)
-        self.emb2out_model = self._emb2out_model.build_model(args)
-
-    @property
-    def _input2emb_model(self):
-        if '_' in self.args.input2emb_model:
-            return MODEL_REGISTRY[self.args.input2emb_model.split('_')[1]+'_enc']
-        else:
-            return MODEL_REGISTRY[self.args.input2emb_model]
-    
-    @property
-    def _pred_model(self):
-        return MODEL_REGISTRY[self.args.pred_model]
-    
-    @property
-    def _emb2out_model(self):
-        if self.args.train_task =='predict':
-            return MODEL_REGISTRY['predout']
-        elif self.args.train_task=='pretrain':
-            return MODEL_REGISTRY['mlmout']
-    
-    @classmethod
-    def build_model(cls, args):
-        """Build a new model instance."""
-        return cls(args)
-
-    def get_logits(self, net_output):
-        return net_output.float()
-
-    def get_targets(self, sample):
-        if self.args.train_task=='predict':
-            return sample['label'].float()
-        
-        elif self.args.train_task=='pretrain':
-            return{
-              victim+'_label' :sample['net_input'][victim+'_label']
-                for victim in self.args.mask_list
-            }
-                
-            
-
-    def forward(self, **kwargs):
-        all_codes_embs = self.input2emb_model(**kwargs)  # (B, S, E)
-        
-        x = self.pred_model(all_codes_embs, **kwargs)
-        net_output = self.emb2out_model(x, **kwargs)
-
-        return net_output
-
diff --git a/models/emb2out.py b/models/emb2out.py
old mode 100644
new mode 100755
index 87eb649..844e8fb
--- a/models/emb2out.py
+++ b/models/emb2out.py
@@ -1,3 +1,4 @@
+import torch
 import torch.nn as nn
 from models import register_model
 
@@ -7,36 +8,12 @@ class PredOutPutLayer(nn.Module):
         super().__init__()
         self.args = args
 
-        self.multi_label_dict = {
-            'mimic3':{
-                'dx':18,
-                'im_disch':17,
-                'fi_ac':18},
-            'eicu':{
-                'dx':18,
-                'im_disch':8,
-                'fi_ac':9},
-             'mimic4':{
-                 'dx':18,
-                 'im_disch':17,
-                 'fi_ac':18},
-            'mimic3_eicu':{
-                  'dx':18,
-                   },
-             'mimic3_mimic4':{
-                   'dx':18,
-                   'im_disch':17,
-                    'fi_ac':18},
-             'mimic3_mimic4_eicu':{
-                     'dx':18,
-                     },
-              }
+        self.final_proj = nn.ModuleDict()
 
-        self.final_proj = nn.Linear(
-            args.pred_dim,
-            self.multi_label_dict[args.src_data][args.pred_target] 
-            if args.pred_target in ['dx', 'fi_ac', 'im_disch'] else 1 
-        ) 
+        for task in self.args.pred_tasks:
+            self.final_proj[task.name] = nn.Linear(
+                args.pred_dim, task.num_classes
+            )
    
     @classmethod
     def build_model(cls, args):
@@ -49,16 +26,20 @@ class PredOutPutLayer(nn.Module):
         if self.args.pred_pooling =='cls':
             x = x[:, 0, :]
         elif self.args.pred_pooling =='mean':
-            if '_' in self.args.input2emb_model: 
+            if self.args.structure =='hi': 
                 mask = ~input_ids[:, :, 1].eq(102)
             else:
                 mask = (input_ids!=0)
             mask = mask.unsqueeze(dim=2).to(x.device).expand(B, S, self.args.pred_dim)
             x = (x*mask).sum(dim=1)/mask.sum(dim=1)
             #x = x.mean(dim=1)
-        output = self.final_proj(x) # B, E -> B, 1
-        output = output.squeeze()
-        return {'pred_output': output}
+        
+        preds = dict()
+
+        for k, layer in self.final_proj.items():
+            preds[k] = layer(x)
+
+        return {'pred_output': preds}
 
 
 @register_model("mlmout")
@@ -67,80 +48,10 @@ class MLMOutPutLayer(nn.Module):
         super().__init__()
 
         self.args = args
-        if self.args.input2emb_model.startswith('codeemb'):
-            input_index_size_dict = {
-                'mimic3' : {#6543
-                    'select' : {'cc': 5372, 'ct':6532},
-                    'whole' :{'cc': 9017, 'ct':10389}
-                },
-                'eicu' : {
-                    'select' : {'cc': 3971, 'ct':4151},
-                    'whole' :{'cc': 5462, 'ct':6305}
-                },
-                'mimic4' : {
-                    'select' : {'cc': 5869, 'ct':5581},
-                    'whole' :{'cc': 10241, 'ct':9568}
-                },
-                
-                # pooled
-                'mimic3_eicu':{
-                    'select' : {'cc': 5869},
-                    'whole' :{'cc': 10241},
-                },
-                
-                'mimic3_mimic4':{
-                    'select' : {'cc': 7771},
-                    'whole' :{'cc': 15356}
-                },
-                'mimic4_eicu':{
-                    'select' : {'cc': 9813},
-                    'whole' :{'cc': 15676},
-                },
-                'mimic3_mimic4_eicu':{
-                    'select' : {'cc': 11716},
-                    'whole' :{'cc': 20792},
-                }
-            }
 
-            type_index_size_dict = {
-                'mimic3' : {
-                    'select' : {'cc': 17, 'ct':9},
-                    'whole' :{'cc': 48, 'ct':10}
-                },
-                'eicu' : {
-                    'select' : {'cc':16, 'ct':10},
-                    'whole' :{'cc': 28, 'ct':10}
-                },
-                'mimic4' : {
-                    'select' : {'cc': 16, 'ct':10},
-                    'whole' :{'cc': 42, 'ct':9}
-                },
-                
-                # pooled
-                'mimic3_eicu':{
-                        'select' : {'cc': 26},
-                        'whole' :{'cc': 69},
-                    },
-                
-                'mimic3_mimic4':{
-                    'select' : {'cc': 16},
-                    'whole' :{'cc': 53}
-                },
-                'mimic4_eicu':{
-                    'select' : {'cc': 25},
-                    'whole' :{'cc': 63},
-                },
-                'mimic3_mimic4_eicu':{
-                    'select' : {'cc': 26},
-                    'whole' :{'cc': 75},
-                }
-            }
-            input_index_size = input_index_size_dict[args.src_data][args.feature][args.column_embed]
-            type_index_size = type_index_size_dict[args.src_data][args.feature][args.column_embed]
-        else:
-            input_index_size = 28996
-            type_index_size = 14
-            dpe_index_size = 25
+        input_index_size = 28996
+        type_index_size = 7
+        dpe_index_size = 16 # for pooled
         
         self.input_ids_out = nn.Linear(
             args.embed_dim,
diff --git a/models/hi_encoder.py b/models/hi_encoder.py
deleted file mode 100644
index 2958fbd..0000000
--- a/models/hi_encoder.py
+++ /dev/null
@@ -1,80 +0,0 @@
-import logging
-from pdb import post_mortem
-
-import torch
-import torch.nn as nn
-from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
-
-from transformers import AutoConfig, AutoModel
-from models import register_model, MODEL_REGISTRY
-from models.transformer import PositionalEncoding
-
-logger = logging.getLogger(__name__)
-
-@register_model("bert_enc")
-class EventEncoder(nn.Module):
-    def __init__(self, args):
-        super().__init__()
-        self.args = args
-        self.pred_dim = args.pred_dim
-
-        self.enc_model = self._enc_model.build_model(args)
-
-        encoder_layers = TransformerEncoderLayer(
-            args.pred_dim,
-            args.n_heads,   # default=8
-            args.pred_dim*4,
-            args.dropout,
-            batch_first=True
-            )
-        
-        self.transformer_encoder = TransformerEncoder(encoder_layers, args.n_layers)
-        self.layer_norm = nn.LayerNorm(args.embed_dim, eps=1e-12)
-
-        self.post_encode_proj = (
-            nn.Linear(bert_model_config[args.bert_model][1], self.pred_dim)
-        )
-   
-        self.mlm_proj = (
-            nn.Linear(bert_model_config[args.bert_model][1], 28996)
-            if args.pretrain_task == "text_encoder_mlm" else None
-        )
-
-    @classmethod
-    def build_model(cls, args):
-        """Build a new model instance."""
-        return cls(args)
-
-    @property
-    def _enc_model(self):
-        return MODEL_REGISTRY[self.args.input2emb_model.split('_')[0]]
-
-    def forward(self, input_ids, **kwargs):
-      
-        B, S, _= input_ids.size()
-        x = self.enc_model(input_ids, **kwargs) # (B*S, W, E)
-     
-        src_pad_mask = input_ids.view(B*S, -1).eq(0).to(x.device) # (B, S, W) -> (B*S, W)
-        encoder_output = self.transformer_encoder(x, src_key_padding_mask=src_pad_mask)
-
-        if (
-            (self.args.train_task == 'pretrain' and self.args.pretrain_task == 'w2v')
-            or (self.args.pretrained_load == 'w2v')
-            or (self.args.apply_mean)
-        ):
-            x = encoder_output
-            x[src_pad_mask] = 0
-            x = torch.div(x.sum(dim=1), (x!=0).sum(dim=1))
-            net_output = self.post_encode_proj(x).view(B, -1, self.pred_dim)
-        else:
-            net_output = (
-                self.post_encode_proj(
-                    encoder_output[:, 0, :]
-                ).view(B, -1, self.pred_dim) 
-            )
-
-        if self.mlm_proj:
-            mlm_output = self.mlm_proj(bert_outputs[0]) # (B x S, W, H) -> (B x S, W, Bert-vocab)
-            return mlm_output
-
-        return net_output
\ No newline at end of file
diff --git a/models/input2emb.py b/models/input2emb.py
old mode 100644
new mode 100755
index 65537bc..b8fb94a
--- a/models/input2emb.py
+++ b/models/input2emb.py
@@ -6,132 +6,13 @@ import torch.nn.functional as F
 from transformers import AutoConfig, AutoModel
 
 from models import register_model
-from models.transformer import PositionalEncoding
+from models.utils import PositionalEncoding
 
 import pickle as pkl
 import os
 import numpy as np
 
-@register_model("codeemb")
-class CodeEmb(nn.Module):
-    def __init__(self, args):
-        super().__init__()
-        self.args = args
-
-        input_index_size_dict = {
-                'mimic3' : {
-                    'select' : 6532,
-                    'whole' :10389
-                },
-                'eicu' : {
-                    'select' : 4151,
-                    'whole' :6305
-                },
-                'mimic4' : {
-                    'select' : 5581,
-                    'whole' :9568
-                },
-                
-                # pooled
-                'mimic3_eicu':{
-                    'select' :  9316,
-                    'whole' : 14452,
-                },
-                
-                'mimic3_mimic4':{
-                    'select' :  7771,
-                    'whole' : 15356
-                },
-                'mimic4_eicu':{
-                    'select' :  9813,
-                    'whole' : 15676,
-                },
-                'mimic3_mimic4_eicu':{
-                    'select' : 11716,
-                    'whole' : 20792,
-                }
-            }
-
-        type_index_size_dict = {
-            'mimic3' : {
-                'select' : 9,
-                'whole' : 10
-            },
-            'eicu' : {
-                'select' : 10,
-                'whole' : 10
-            },
-            'mimic4' : {
-                'select' : 10,
-                'whole' : 9
-            },
-            
-            # pooled
-            'mimic3_eicu':{
-                    'select' : 26,
-                    'whole' : 69,
-                },
-            
-            'mimic3_mimic4':{
-                'select' : 16,
-                'whole' : 53
-            },
-            'mimic4_eicu':{
-                'select' :  25,
-                'whole' : 63,
-            },
-            'mimic3_mimic4_eicu':{
-                'select' :  26,
-                'whole' : 75,
-            }
-        }
-        
-        if args.train_type=='transfer':
-            data = args.eval_data[0]
-
-        self.input_index_size = input_index_size_dict[data][args.feature][args.column_embed]
-        self.type_index_size = type_index_size_dict[data][args.feature][args.column_embed]
-
-        self.input_ids_embedding =nn.Embedding(self.input_index_size, args.embed_dim, padding_idx=0)
-        self.type_ids_embedding =nn.Embedding(self.type_index_size, args.embed_dim, padding_idx=0)
-        
-
-        max_len = args.max_word_len if '_' in args.input2emb_model else args.max_seq_len
-        
-        self.pos_encoder = PositionalEncoding(  
-            args.embed_dim, args.dropout, max_len
-            ) if self.args.pos_enc else None
-
-        self.layer_norm = nn.LayerNorm(args.embed_dim, eps=1e-12)
-        self.dropout = nn.Dropout(args.dropout)
-
-    
-    @classmethod
-    def build_model(cls, args):
-        """Build a new model instance."""
-        return cls(args)
-    
-
-    def forward(self, input_ids, type_ids, **kwargs):
-        B, S= input_ids.shape[0], input_ids.shape[1]
-    
-        x = self.input_ids_embedding(input_ids)
-
-        if self.args.mapping:
-            x = self.mapping_matrix(x)
-        
-        if self.type_ids_embedding: 
-            x += self.type_ids_embedding(type_ids) 
-        
-        if '_' in self.args.input2emb_model:
-            x = x.view(B*S, -1, self.args.embed_dim) 
-            
-        if self.pos_encoder:   
-            x = self.pos_encoder(x) # (B, S, W, E) -> (B*S, W, E)
-        x = self.dropout(self.layer_norm(x))
-        return x
-
-
+import math
 
 @register_model("descemb")
 class DescEmb(nn.Module):
@@ -140,9 +21,9 @@ class DescEmb(nn.Module):
         
         self.args = args
         
-        self.input_index_size = 28119 #28996 # bio clinical bert vocab
-        self.type_index_size = 14 # mimic3 + eicu + mimic4
-        self.dpe_index_size = 25
+        self.input_index_size = 28996 # bio clinical bert vocab
+        self.type_index_size = 7 
+        self.dpe_index_size = 16
 
         self.dpe = args.dpe
         self.token_type = args.type_token
@@ -160,12 +41,11 @@ class DescEmb(nn.Module):
         ) if self.args.type_token else None
 
         self.dpe_ids_embedding =nn.Embedding(
-            self.dpe_index_size, self.args.embed_dim, padding_idx=0
+            self.dpe_index_size, self.args.embed_dim
         ) if self.args.dpe else None
 
-        max_len = args.max_word_len if '_' in args.input2emb_model else args.max_seq_len
-        max_len = args.note_max_seq_len if args.note_max_seq_len > max_len else max_len
-
+        max_len = args.max_seq_len if args.structure =='fl' else args.max_word_len
+   
         self.pos_encoder = PositionalEncoding(  
             args.embed_dim, args.dropout, max_len
             ) if self.pos_enc else None
@@ -181,16 +61,30 @@ class DescEmb(nn.Module):
         for victim, weight in load_dict:
             getattr(self, victim+'_embedding').from_pretrained(weight) 
 
-    def forward(self, input_ids, type_ids, dpe_ids, only_features=False, **kwargs):
-        B, S = input_ids.shape[0], input_ids.shape[1]
+    def forward(self, input_ids, type_ids, dpe_ids, times, only_features=False, **kwargs): # TODO: add time token - 각 token 벡터(shape: 128) 에 sinosoidal k = time token 더해줌
+        B, S = input_ids.shape[0], input_ids.shape[1] # time: hi - (B, S, 1), fl - (B, S, 1)
         
         x = self.input_ids_embedding(input_ids)
 
+        if only_features:
+            if self.pos_encoder:
+                x = self.pos_encoder(x)
+                return x
+
         if self.type_ids_embedding: # column description mean 
             x += self.type_ids_embedding(type_ids) 
 
         if self.dpe_ids_embedding:
             x += self.dpe_ids_embedding(dpe_ids)
+
+        if self.args.time_embed == 'encoder' and self.args.structure=='hi': #TODO: flatten
+            W = input_ids.shape[2]
+            times = times.unsqueeze(-1).repeat(1, 1, W).unsqueeze(-1) # (B, S, W, 1)
+            div_term = torch.exp(torch.arange(0, self.args.embed_dim, 2) * (-math.log(10000.0) / self.args.embed_dim)).to(x.device) # (embed_dim/2, )
+            pe = torch.zeros(B, S, W, self.args.embed_dim) # (B, S, W, embed_dim)
+            pe[:, :, :, 0::2] = torch.sin(times * div_term) # (B, S, W, embed_dim)
+            pe[:, :, :, 1::2] = torch.cos(times * div_term)
+            x = x + pe.to(x.device) 
         
         if self.args.structure=='hi':
             x = x.view(B*S, -1, self.args.embed_dim) 
diff --git a/models/performer.py b/models/performer.py
old mode 100644
new mode 100755
index e017660..e1faf1a
--- a/models/performer.py
+++ b/models/performer.py
@@ -6,14 +6,22 @@ import torch.nn.functional as F
 
 from performer_pytorch import Performer
 from models import register_model
-from models.transformer import PositionalEncoding
+from models.utils import PositionalEncoding
 
 @register_model("performer")
-class EncoderPerformer(nn.Module):
+class Performer(nn.Module):
     def __init__(self, args):
         super().__init__()
         
         self.args = args
+
+        self.pos_encoder = None
+        if args.structure =='hi':
+            self.pos_encoder = PositionalEncoding(
+                args.pred_dim, args.dropout, args.max_seq_len
+                )
+            self.layer_norm = nn.LayerNorm(args.embed_dim, eps=1e-12)
+
         self.performer_encoder = Performer(
             dim = args.pred_dim,
             depth = args.n_layers,
@@ -42,13 +50,6 @@ class EncoderPerformer(nn.Module):
             shift_tokens = True
         )
 
-        self.pos_encoder = None
-        if '_' in args.input2emb_model:
-            self.pos_encoder = PositionalEncoding(
-                args.pred_dim, args.dropout, args.max_seq_len
-                )
-            self.layer_norm = nn.LayerNorm(args.embed_dim, eps=1e-12)
-
     @classmethod
     def build_model(cls, args):
         """Build a new model instance."""
@@ -57,7 +58,7 @@ class EncoderPerformer(nn.Module):
     def forward(self, x, input_ids, **kwargs):
         # input_ids: (B, S)
         B, S = input_ids.shape[0], input_ids.shape[1]
-        if '_' in self.args.input2emb_model: 
+        if self.args.structure =='hi': 
             src_pad_mask = input_ids[:, :, 1].eq(0).to(x.device)
         else:
             src_pad_mask = input_ids.eq(0).to(x.device) 
diff --git a/models/transformer.py b/models/transformer.py
deleted file mode 100644
index 70b08c6..0000000
--- a/models/transformer.py
+++ /dev/null
@@ -1,91 +0,0 @@
-import math
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from torch.nn.modules.batchnorm import BatchNorm1d
-from torch.nn.modules.container import Sequential
-import numpy as np
-
-from torch.nn import TransformerEncoder, TransformerEncoderLayer
-from models import register_model
-
-@register_model("transformer")
-class EncoderTransformer(nn.Module):
-    def __init__(self, args):
-        super().__init__()
-        
-        self.args = args
-        encoder_layers = TransformerEncoderLayer(
-            args.pred_dim,
-            args.n_heads,   # default=8
-            args.pred_dim*4,
-            args.dropout,
-            batch_first=True
-            )
-        
-        self.transformer_encoder = TransformerEncoder(encoder_layers, args.n_layers)
-        self.pos_encoder = PositionalEncoding(
-            args.pred_dim, args.dropout, args.max_seq_len
-            ) if '_' in args.input2emb_model else None
-
-        self.layer_norm = nn.LayerNorm(args.embed_dim, eps=1e-12)
-
-    @classmethod
-    def build_model(cls, args):
-        """Build a new model instance."""
-        return cls(args)
-
-    def forward(self, x, input_ids, **kwargs):
-        # input_ids: (B, S) (B x S, W ) -> (Bx s, W) -> (B, s, W)
-                      
-        B, S = input_ids.shape[0], input_ids.shape[1]
-        if '_' in self.args.input2emb_model: 
-            src_pad_mask = input_ids[:, :, 1].eq(0).to(x.device)
-        else:
-            src_pad_mask = input_ids.eq(0).to(x.device) 
-        
-        src_mask= None
-        
-        '''
-        Note: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked positions. 
-                    If a ByteTensor is provided, 
-                        the non-zero positions are not allowed to attend
-                        while the zero positions will be unchanged. 
-
-                    If a BoolTensor is provided, 
-                        positions with ``True`` are not allowed to attend 
-                        while ``False`` values will be unchanged. 
-
-                    If a FloatTensor is provided, it will be added to the attention weight. 
-                    https://pytorch.org/docs/sfeature/generated/torch.nn.Transformer.html
-
-        '''
-        if self.pos_encoder is not None:
-            x = self.layer_norm(self.pos_encoder(x))
-        encoder_output = self.transformer_encoder(x, mask=src_mask, src_key_padding_mask=src_pad_mask)
-
-        return encoder_output
-
-  
-
-class PositionalEncoding(nn.Module):
-
-    def __init__(self, d_model, dropout, max_len):
-        super().__init__()
-        self.dropout = nn.Dropout(p=dropout)
-        position = torch.arange(max_len).unsqueeze(1)
-        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
-        pe = torch.zeros(1, max_len, d_model)
-        pe[0, :, 0::2] = torch.sin(position * div_term)
-        pe[0, :, 1::2] = torch.cos(position * div_term)
-        self.register_buffer('pe', pe)
-
-    def forward(self, x): 
-        """
-        Args:
-            x: Tensor, shape [batch_size, seq_len, embedding_dim]
-        """
-
-        x = x + self.pe[:, :x.size(1)]
-        return self.dropout(x)
\ No newline at end of file
diff --git a/models/wav2vec2.py b/models/wav2vec2.py
deleted file mode 100644
index fc80aab..0000000
--- a/models/wav2vec2.py
+++ /dev/null
@@ -1,324 +0,0 @@
-import logging
-
-import torch
-import torch.nn as nn
-
-from utils import utils
-from utils.data_utils import compute_mask_indices
-from models import register_model, MODEL_REGISTRY
-from modules import (
-    GradMultiply,
-    GumbelVectorQuantizer,
-    LayerNorm
-)
-
-logger = logging.getLogger(__name__)
-
-@register_model('wav2vec2')
-class Wav2Vec2Model(nn.Module):
-    def __init__(self, args):
-        super().__init__()
-        self.args = args
-
-        self.num_updates = 0
-
-        self.final_dim = args.final_dim
-        self.feature_grad_mult = args.feature_grad_mult
-
-        self.mask_prob = args.mask_prob
-        self.mask_length = args.mask_length
-        self.mask_selection = args.mask_selection
-        self.mask_other = args.mask_other
-        self.no_mask_overlap = args.no_mask_overlap
-        self.mask_min_space = args.mask_min_space
-
-        self.n_negatives = args.num_negatives
-        self.codebook_negatives = args.codebook_negatives
-        self.cross_sample_negatives = 0
-
-        self.logit_temp = args.logit_temp
-
-        self.input2emb_model = self._input2emb_model.build_model(args)
-
-        self.quantizer = GumbelVectorQuantizer(
-            dim=args.embed_dim,
-            num_vars=args.latent_vars,
-            temp=args.latent_temp,
-            groups=args.latent_groups,
-            combine_groups=False,
-            vq_dim=args.embed_dim,
-            time_first=True,
-        )
-
-        self.pred_model = self._pred_model.build_model(args)
-
-        self.layer_norm = LayerNorm(args.embed_dim)
-        self.dropout_input = nn.Dropout(args.dropout_input)
-        self.dropout_features = nn.Dropout(args.dropout_features)
-        self.project_q = nn.Linear(args.embed_dim, self.final_dim)
-        self.final_proj = nn.Linear(args.embed_dim, self.final_dim)
-        self.mask_emb = nn.Parameter(
-            torch.FloatTensor(args.embed_dim).uniform_()
-        )
-
-    @property
-    def _input2emb_model(self):
-        if '_' in self.args.input2emb_model:
-            return MODEL_REGISTRY[self.args.input2emb_model.split('_')[1]+'_enc']
-        else:
-            return MODEL_REGISTRY[self.args.input2emb_model]
-    
-    @property
-    def _pred_model(self):
-        return MODEL_REGISTRY[self.args.pred_model]
-
-    @classmethod
-    def build_model(cls, args):
-        return cls(args)
-
-    def sample_negatives(self, y, num):
-
-        if self.n_negatives == 0 and self.cross_sample_negatives == 0:
-            return y.new(0)
-        
-        batch_size, time_size, feature_size = y.shape
-        y = y.view(-1, feature_size) # B x T x C -> (B x T) x C
-
-        cross_high = time_size * batch_size
-        high = time_size
-        with torch.no_grad():
-            assert high > 1, f"{batch_size, time_size, feature_size}"
-
-            if self.n_negatives > 0:
-                time_sizes = (
-                    utils.buffered_arange(num)
-                    .unsqueeze(-1)
-                    .expand(-1, self.n_negatives)
-                    .flatten()
-                )
-                neg_idxs = torch.randint(
-                    low = 0, high = high - 1, size = (batch_size, self.n_negatives * num)
-                )
-                neg_idxs[neg_idxs >= time_sizes] += 1
-
-            if self.cross_sample_negatives > 0:
-                time_sizes = (
-                    utils.buffered_arange(num)
-                    .unsqueeze(-1)
-                    .expand(-1, self.cross_sample_negatives)
-                    .flatten()
-                )
-
-                cross_neg_idxs = torch.randint(
-                    low = 0,
-                    high = cross_high - 1,
-                    size = (batch_size, self.cross_sample_negatives * num)
-                )
-                cross_neg_idxs[cross_neg_idxs >= time_sizes] += 1
-        
-        if self.n_negatives > 0:
-            for i in range(1, batch_size):
-                neg_idxs[i] += i * high
-        else:
-            neg_idxs = cross_neg_idxs
-
-        if self.cross_sample_negatives > 0 and self.n_negatives > 0:
-            neg_idxs = torch.cat([neg_idxs, cross_neg_idxs], dim =1)
-
-        negs = y[neg_idxs.view(-1)]
-        negs = negs.view(
-            batch_size, num, self.n_negatives + self.cross_sample_negatives, feature_size
-        ).permute(
-            2, 0, 1, 3
-        ) # to N x B x T x C
-
-        return negs, neg_idxs
-    
-    def compute_preds(self, x, y, negatives):
-
-        neg_is_pos = (y == negatives).all(-1)
-        y = y.unsqueeze(0)
-        targets = torch.cat([y, negatives], dim= 0)
-
-        logits = torch.cosine_similarity(x.float(), targets.float(), dim=-1)
-
-        logits = logits / self.logit_temp
-        logits = logits.type_as(x)
-
-        if neg_is_pos.any():
-            logits[1:][neg_is_pos] = float("-inf")
-
-        return logits
-
-    def apply_mask(
-        self,
-        x,
-        padding_mask,
-        mask_indices = None,
-        ):
-        B, T, C = x.shape
-        
-        if self.mask_prob > 0:
-            if mask_indices is None:
-                mask_indices = compute_mask_indices(
-                    (B, T),
-                    padding_mask,
-                    self.mask_prob,
-                    self.mask_length,
-                    self.mask_selection,
-                    self.mask_other,
-                    min_masks = 2,
-                    no_overlap = self.no_mask_overlap,
-                    min_space = self.mask_min_space,
-                )
-                mask_indices = torch.from_numpy(mask_indices).to(x.device)
-            x[mask_indices] = self.mask_emb
-        else:
-            mask_indices = None
-        
-        return x, mask_indices
-
-    def forward(
-        self,
-        input_ids,
-        mask=True,
-        features_only=False,
-        mask_indices=None,
-        **kwargs
-    ):
-        if self.feature_grad_mult > 0:
-            features = self.input2emb_model(input_ids=input_ids, **kwargs)
-            if self.feature_grad_mult != 0:
-                features = GradMultiply.apply(features, self.feature_grad_mult)
-        else:
-            with torch.no_grad():
-                features = self.input2emb_model(input_ids=input_ids, **kwargs)
-        
-        features_pen = features.float().pow(2).mean()
-
-        features = self.layer_norm(features)
-        unmasked_features = features.clone()
-
-        features = self.dropout_input(features)
-        unmasked_features = self.dropout_features(unmasked_features)
-
-        num_vars = None
-        code_ppl = None
-        prob_ppl = None
-        curr_temp = None
-
-        if '_' in self.args.input2emb_model:
-            padding_mask = input_ids[:, :, 1].eq(0).to(features.device)
-        else:
-            padding_mask = input_ids.eq(0).to(features.device)
-
-        if mask:
-            x, mask_indices = self.apply_mask(
-                features,
-                padding_mask,
-                mask_indices=mask_indices
-            )
-            if mask_indices is not None:
-                y = unmasked_features[mask_indices].view(
-                    unmasked_features.size(0), -1, unmasked_features.size(-1)
-                )
-            else:
-                y = unmasked_features
-        else:
-            x = features
-            y = unmasked_features
-            mask_indices = None
-
-        x = self.pred_model(x, input_ids)
-
-        if features_only:
-            return {"x": x, "features": unmasked_features}
-        
-        if self.quantizer:
-            q = self.quantizer(y, produce_targets=False)
-            y = q['x']
-            num_vars = q['num_vars']
-            code_ppl = q['code_perplexity']
-            prob_ppl = q['prob_perplexity']
-            curr_temp = q['temp']
-
-            y = self.project_q(y)
-
-            negs, _ = self.sample_negatives(y, y.size(1))
-
-            if self.codebook_negatives > 0:
-                cb_negs = self.quantizer.sample_from_codebook(
-                    y.size(0) * y.size(1), self.codebook_negatives
-                )
-                cb_negs = cb_negs.view(
-                    self.codebook_negatives, y.size(0), y.size(1), -1
-                )
-                cb_negs = self.project_q(cb_negs)
-                negs = torch.cat([negs, cb_negs], dim=0)
-        else:
-            y = self.project_q(y)
-
-            negs, _ = self.sample_negatives(y, y.size(1))
-        
-        x = x[mask_indices].view(x.size(0), -1, x.size(-1))
-
-        x = self.final_proj(x)
-        x = self.compute_preds(x, y, negs)
-
-        result = {'x': x, 'features_pen': features_pen, 'mask_indices': mask_indices}
-        if prob_ppl is not None:
-            result["prob_perplexity"] = prob_ppl
-            result["code_perplexity"] = code_ppl
-            result["num_vars"] = num_vars
-            result["temp"] = curr_temp
-
-        return result
-
-    def quantize(self, input_ids, **kwargs):
-        assert self.quantizer is not None
-        x = self.input2emb_model(input_ids, **kwargs)
-        x = self.layer_norm(x)
-        return self.quantizer.forward_idx(x)
-
-    def extract_features(self, input_ids, mask=False, **kwargs):
-        res = self.forward(input_ids=input_ids, mask=mask, features_only=True, **kwargs)
-        return res
-
-    def get_logits(self, net_output):
-        logits = net_output["x"]
-        logits = logits.transpose(0,2)
-        logits = logits.reshape(-1, logits.size(-1))
-        return logits
-    
-    def get_targets(self, sample, net_output, expand_steps=True):
-        x = net_output["x"]
-        return x.new_zeros(x.size(1) * x.size(2), dtype = torch.long)
-
-    def get_extra_losses(self, net_output):
-        pen = []
-
-        if "prob_perplexity" in net_output:
-            pen.append(
-                (net_output["num_vars"] - net_output["prob_perplexity"])
-                / net_output["num_vars"]
-            )
-
-        if "features_pen" in net_output:
-            pen.append(net_output["features_pen"])
-
-        return pen
-
-    def remove_pretraining_modules(self):
-        self.layer_norm = None
-        self.dropout_input = None
-        self.dropout_features = None
-        self.quantizer = None
-        self.project_q = None
-        self.final_proj = None
-        self.mask_emb = None
-    
-    def set_num_updates(self, num_updates):
-        self.num_updates = num_updates
-        for m in self.modules():
-            if hasattr(m, "set_num_updates") and m != self:
-                m.set_num_updates(num_updates)
\ No newline at end of file
diff --git a/preprocess/ICU_class.py b/preprocess/ICU_class.py
old mode 100644
new mode 100755
diff --git a/preprocess/covert2numpy.py b/preprocess/covert2numpy.py
old mode 100644
new mode 100755
diff --git a/preprocess/datasets_construct.py b/preprocess/datasets_construct.py
old mode 100644
new mode 100755
diff --git a/preprocess/icuclass_gen.py b/preprocess/icuclass_gen.py
old mode 100644
new mode 100755
diff --git a/preprocess/main_preprocess.py b/preprocess/main_preprocess.py
old mode 100644
new mode 100755
diff --git a/preprocess/preprocess_utils.py b/preprocess/preprocess_utils.py
old mode 100644
new mode 100755
diff --git a/trainers/__init__.py b/trainers/__init__.py
old mode 100644
new mode 100755
index de8ad9b..94f1e92
--- a/trainers/__init__.py
+++ b/trainers/__init__.py
@@ -1,11 +1,9 @@
 from .base_trainer import BaseTrainer
-from .mlm_trainer import MLMTranier
-from .note_trainer import NoteTrainer
-from .w2v_trainer import W2VTrainer
+#rom .mlm_trainer import MLMTranier
+#from .w2v_trainer import W2VTrainer
 
 __all__ = [
     'BaseTrainer',
-    'MLMTrainer',
-    'NoteTrainer',
-    'W2VTrainer'
+    #'MLMTrainer',
+    #'W2VTrainer'
 ]
\ No newline at end of file
diff --git a/trainers/base_trainer.py b/trainers/base_trainer.py
old mode 100644
new mode 100755
index 515c5b4..ce36cd9
--- a/trainers/base_trainer.py
+++ b/trainers/base_trainer.py
@@ -1,132 +1,69 @@
-import os
-import wandb
+import logging
+import math
+import time
 from itertools import chain
 from typing import Any, Dict, List
-import logging
 
-import numpy as np
 import torch
 import torch.nn as nn
+import torch.nn.functional as F
+import torch.multiprocessing as mp
 
-from metrics.metric import PredMetric, PretrainMetric
-import models
+from torch.optim import Adam
+from torch.nn.parallel import DistributedDataParallel
 
-import utils.trainer_utils as utils
+import utils.utils as utils
 import utils.distributed_utils as distributed_utils
-from torch.utils.data import DataLoader, ConcatDataset
-from loss.loss import PredLoss, PretrainLoss
-from datasets.base_dataset import HierarchicalEHRDataset, UnifiedEHRDataset
-import tqdm
-
-import torch.multiprocessing as mp
-from torch.nn.parallel import DistributedDataParallel
-from torch.utils.data.distributed import DistributedSampler
-import torch.distributed as dist
+from loggings import metrics
+from loggings.meters import safe_round
 
 logger = logging.getLogger(__name__)
 
-class BaseTrainer:
-    def __init__(self, args, seed):
+class BaseTrainer(object):
+    def __init__(
+        self,
+        args,
+        model,
+        criterion,
+    ):
         self.args = args
-        self.seed = seed
-        self.batch_size = args.batch_size
-        self.save_dir = args.save_dir
-        self.save_prefix = args.save_prefix
-        
-        if args.train_type =='transfer':
-            self.train_data = args.eval_data[0]
+        self.cuda = torch.cuda.is_available()
+        if self.cuda:
+            self.device = torch.device('cuda')
         else:
-            self.train_data = args.src_data
+            self.device = torch.device('cpu')
+        
+        self._criterion = criterion
+        self._model = model
 
-        self.datasets = dict()
-        self.early_stopping_dict = dict()
+        self._criterion = self._criterion.to(device=self.device)
+        self._model = self._model.to(device=self.device)
 
+        self._num_updates = 0
 
-        data_types = ['train'] + sorted(self.args.valid_subsets*len(self.args.eval_data))
-        data_names = [self.train_data] + self.args.eval_data*len(self.args.valid_subsets)
-        vocab = self.train_data
-        
-        logger.info(data_types, data_names)
-        for split, data in zip(data_types, data_names):
-            # logger.info('split : ', split, 'data_name : ', data)
-            if not split in self.datasets.keys():
-                self.datasets[split] = dict()
-            self.datasets[split][data] = self.load_dataset(split, data, vocab, self.seed)
-        
-
-    def load_dataset(self, split, dataname, vocab, seed) -> None: 
-        if self.args.structure == 'hi':
-            dataset = HierarchicalEHRDataset(
-                data=dataname,
-                input_path=self.args.input_path,
-                split=split,
-                vocab=vocab,
-                concept=self.args.input2emb_model,
-                feature=self.args.feature,
-                train_task=self.args.train_task,
-                pretrain_task=self.args.pretrain_task,
-                ratio=self.args.ratio,
-                pred_target=self.args.pred_target,
-                seed=self.args.seed,
-                mask_list=self.args.mask_list,
-                mlm_prob=self.args.mlm_prob,
-                max_word_len=self.args.max_word_len,
-                max_seq_len=self.args.max_seq_len,
-            )
-        elif self.args.structure == 'fl':
-            dataset = UnifiedEHRDataset(
-                data=dataname,
-                input_path=self.args.input_path,
-                split=split,
-                vocab=vocab,
-                concept=self.args.input2emb_model,
-                feature=self.args.feature,
-                train_task=self.args.train_task,
-                pretrain_task=self.args.pretrain_task,
-                ratio=self.args.ratio,
-                pred_target=self.args.pred_target,
-                seed=self.args.seed,
-                mask_list=self.args.mask_list,
-                mlm_prob=self.args.mlm_prob,
-                max_seq_len=self.args.max_seq_len,
-            )
+        self._optimizer = None
+        self._wrapped_criterion = None
+        self._wrapped_model = None
 
+        if self.cuda:
+            self.cuda_env = utils.CudaEnvironment()
+            if self.data_parallel_world_size > 1:
+                self.cuda_env_arr = distributed_utils.all_gather_list(
+                    self.cuda_env, group=self.data_parallel_process_group
+                )
+            else:
+                self.cuda_env_arr = [self.cuda_env]
+            if self.data_parallel_rank == 0:
+                utils.CudaEnvironment.pretty_print_cuda_env_list(self.cuda_env_arr)
         else:
-            raise NotImplementedError(self.model_type)
- 
-        return dataset
-
-    def dataloader_set(self, dataset, world_size, batch_size):
-        if 1 < world_size:
-            self.sampler = DistributedSampler(dataset)
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size=batch_size,
-                num_workers=8,
-                sampler=self.sampler,
-                pin_memory=True,
-            )
-        else:
-            self.sampler=None
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size=batch_size, 
-                num_workers=8,
-                shuffle=True,
-                pin_memory=True,
-            )
-        return data_loader
-
-    def setup_dist(self, rank, world_size):
-        os.environ['MASTER_ADDR'] = 'localhost'
-        os.environ['MASTER_PORT'] = self.args.port
-        dist.init_process_group(
-            backend = "nccl",
-            rank = rank,
-            world_size = world_size
-        )
+            self.cuda_env = None
+            self.cuda_env_arr = None
+
+        metrics.log_start_time('wall', priority=790, round=0)
+
+        self._start_time = time.time()
+        self._previous_training_time = 0
+        self._cumulative_training_time = None
 
     @property
     def data_parallel_world_size(self):
@@ -148,297 +85,228 @@ class BaseTrainer:
     def is_data_parallel_master(self):
         return self.data_parallel_rank == 0
 
-    def train(self):
-        if 1 < self.args.world_size:
-            mp.spawn(self.distributed_train,
-                    args=(self.args.world_size,),
-                    nprocs=self.args.world_size,
-                    join=True)
-        else:
-            self.distributed_train(self.args.device_num, self.args.world_size)    
-
-    def distributed_train(self, rank, world_size):
-        if 1 < world_size:
-            self.setup_dist(rank, world_size)
-            torch.cuda.set_device(rank)
-
-        # Wandb init
-        if self.is_data_parallel_master and not self.args.debug:
-            wandb.init(
-                project=self.args.wandb_project_name,
-                entity="kaggle-wandb",
-                config=self.args,
-                reinit=True
+    @property
+    def use_distributed_wrapper(self) -> bool:
+        return self.data_parallel_world_size > 1
+    
+    @property
+    def criterion(self):
+        if self._wrapped_criterion is None:
+            if utils.has_parameters(self._criterion) and self.use_distributed_wrapper:
+                self._wrapped_criterion = DistributedDataParallel(
+                    module=self._criterion.to(self.device),
+                    device_ids=[self.args.device_id],
+                    output_device=self.args.device_id,
+                    broadcast_buffers=False,
+                    bucket_cap_mb=25,
+                    process_group=self.data_parallel_process_group,
+                    find_unused_parameters=False,
+                )
+            else:
+                self._wrapped_criterion = self._criterion
+        return self._wrapped_criterion
+    
+    @property
+    def model(self):
+        if self._wrapped_model is None:
+            if self.use_distributed_wrapper:
+                self._wrapped_model = DistributedDataParallel(
+                    module=self._model.to(self.device),
+                    device_ids=[self.args.device_id],
+                    output_device=self.args.device_id,
+                    broadcast_buffers=False,
+                    bucket_cap_mb=25,
+                    process_group=self.data_parallel_process_group,
+                    find_unused_parameters=False,
+                )
+            else:
+                self._wrapped_model = self._model
+        return self._wrapped_model
+    
+    @property
+    def optimizer(self):
+        if self._optimizer is None:
+            self._build_optimizer()
+            if (self.args.auto_resume and self.args.resume) or self.args.edlab_resume:
+                print('loading optimizer from ', self.args.ckpt_load_path)
+                state_dict = torch.load(self.args.ckpt_load_path, map_location='cpu')['optimizer']
+                self._optimizer.load_state_dict(state_dict)
+        return self._optimizer
+    
+    def _build_optimizer(self):
+        params = list(
+            filter(
+                lambda p: p.requires_grad,
+                chain(self.model.parameters(), self.criterion.parameters())
             )
-            wandb.run.name = self.args.wandb_run_name
-
-        model = models.build_model(self.args)
-        num_params = utils.count_parameters(model)
-        
-        if 1 < world_size:
-            device = torch.device(f'cuda:{rank}' if torch.cuda.is_available() else 'cpu')
-            self.model = model.to(device)
-            self.model = DistributedDataParallel(self.model, device_ids=[rank], find_unused_parameters=False)
-        else:
-            self.model = nn.DataParallel(model, device_ids=self.args.device_ids).to('cuda')
-            
-        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)  
-                  
-        if self.args.train_type =='transfer':
-            load_path = self.save_path(self.args.src_data).replace('transfer', 'single') +'.pkl'
-            logger.info('transfer learning, load model from : ', load_path)
-            state_dict = torch.load(load_path, map_location='cpu')['model_state_dict']
-            if self.args.input2emb_model.startswith('codeemb'):
-                state_dict = {
-                    k: v for k,v in state_dict.items() if (
-                        ('input2emb' not in k) and ('pos_enc' not in k)
-                    )
-                }
-            else:   
-                state_dict = {
-                        k: v for k,v in state_dict.items() if (
-                            'pos_enc' not in k
-                        )
-                    }       
-            
-            self.model.load_state_dict(state_dict, strict = False)
-            print('transfer learning mode -- ratio : ', self.args.ratio)
-
-        logger.info(f'device_ids = {self.args.device_ids}')
-
-        data_loader = self.dataloader_set(
-            self.datasets['train'][self.train_data],
-            world_size,
-            self.args.batch_size
         )
 
-        Loss = PredLoss if self.args.train_task =='predict' else PretrainLoss
-        self.criterion = Loss(self.args)
+        if self.cuda and torch.cuda.get_device_capability(0)[0] >= 7:
+            self._optimizer = Adam(params, lr=self.args.lr, weight_decay=0.001)
 
-        metric = PredMetric if self.args.train_task =='predict' else PretrainMetric
-        self.metric = metric(self.args)
+    @metrics.aggregate('train')
+    def train_step(self, sample):
+        self._set_seed()
+        self.model.train()
+        self.criterion.train()
+        self.zero_grad()
 
-        for data in self.datasets['valid'].keys():
-            self.early_stopping_dict[data] = utils.EarlyStopping(
-                patience=self.args.patience, 
-                compare=self.metric.compare,
-                metric=self.metric.update_target
-            )
+        metrics.log_start_time('train_wall', priority=800, round=0)
 
-        break_token= False
-        start_epoch = load_dict['n_epoch'] if load_dict is not None else 1
-        if not self.args.ratio=='0':
-            for n_epoch in range(start_epoch, self.args.epochs + 1):
-                
-                logger.info('[Epoch] {}'.format(n_epoch))
-                self.model.train()
-
-                for iter, sample in tqdm.tqdm(enumerate(data_loader)):
-                    self.optimizer.zero_grad(set_to_none=True)
-                    
-                    output = self.model(**sample['net_input'])
-                    target = self.model.module.get_targets(sample)
-                    
-                    loss = self.criterion(output, target)
-                    loss.backward()
-                    
-                    self.optimizer.step()
-
-                    preds = torch.sigmoid(output['pred_output']).view(-1).detach()
-                    truths = target.view(-1)
-
-                    logging_outputs = {
-                        'loss': float(loss.detach().cpu()),
-                        'preds': preds,
-                        'truths': truths,
-                    }
-                    if self.data_parallel_world_size > 1:
-                        _logging_outputs = self._all_gather_list_sync([logging_outputs])
-
-                        for key in logging_outputs.keys():
-                            if key == 'loss':
-                                logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-                            elif key in ['preds', 'truths']:
-                                logging_outputs[key] = np.concatenate(
-                                    [log[key].numpy() for log in _logging_outputs]
-                                )
-                            else:
-                                raise NotImplementedError(
-                                    "What else?"
-                                )
-                        del _logging_outputs
-                    else:
-                        logging_outputs['preds'] = logging_outputs['preds'].cpu().numpy()
-                        logging_outputs['truths'] = logging_outputs['truths'].cpu().numpy()
-                    
-                    self.metric(**logging_outputs) # iter_uddate
-                    
-                with torch.no_grad():
-                    train_metric_dict = self.metric.get_epoch_dict(
-                        len(data_loader)
-                    )
-        
-                log_dict = utils.log_from_dict(train_metric_dict, 'train', self.train_data, n_epoch)
-                
-                if self.is_data_parallel_master and self.args.debug == False:
-                    wandb.log(log_dict) 
+        logging_outputs = []
+        sample = utils.prepare_sample(sample)
 
-                break_token = self.evaluation(n_epoch)
+        loss, sample_size, logging_output = self.criterion(self.model, sample)
+        logger.info('loss get')
+        loss.backward() # backwward
+        logger.info('loss backward')
+        self.optimizer.step()
         
-                if break_token:
-                    break
+        logging_outputs.append(logging_output)
+        if logging_output['bilirubin']['_y_true'].sum() == -1600:
+            logger.info(f"{logging_output['bilirubin']['_y_true']}")
+        
+        if self.cuda and self.get_num_updates() == 0:
+            torch.cuda.empty_cache()
+    
+        sample_size = float(sample_size)
         
-        self.test(n_epoch)
-        print(f'test finished at epoch {n_epoch}')
+        if self._sync_stats():
+            train_time = self._local_cumulative_training_time()
+            
+            logging_outputs, ( 
+                sample_size, total_train_time
+            ) = self._aggregate_logging_outputs(
+                logging_outputs, sample_size, train_time
+            )
+            logger.info('agg logging output')
+            self._cumulative_training_time = (
+                total_train_time / self.data_parallel_world_size
+            )
+            
+        logger.info('log output sync')
 
-        if self.is_data_parallel_master and self.args.debug == False:
-            wandb.finish(0)
+        logging_output = None
+        self.set_num_updates(self.get_num_updates() + 1)
 
-        if self.data_parallel_world_size > 1:
-            dist.destroy_process_group()
+        if self.cuda and self.cuda_env is not None:
+            gb_used = torch.cuda.max_memory_allocated() / 1024 / 1024 / 1024
+            torch.cuda.reset_peak_memory_stats()
+            gb_free = self.cuda_env.total_memory_in_GB - gb_used
+            metrics.log_scalar(
+                'gb_free', gb_free, priority=1500, round=1, weight=0
+            )
 
+        logging_outputs = list(map(
+            lambda x: {key: x[key] for key in x}, logging_outputs)
+        )
+        
+        logging_output = self._reduce_and_log_stats(
+            self.args.train_src, logging_outputs, sample_size
+        )
+        logger.info('logging output reduce')
+        metrics.log_stop_time('train_wall')
+        return logging_output
 
-    def inference(self, data_loader, data_type, data_name, n_epoch):
-        self.model.eval()
+    @metrics.aggregate('valid')
+    def valid_step(self, sample, subset=None, dataname=None):
         with torch.no_grad():
-            for iter, sample in tqdm.tqdm(enumerate(data_loader)):
-                self.optimizer.zero_grad(set_to_none=True)
-                
-                output = self.model(**sample['net_input'])
-                target = self.model.module.get_targets(sample)
-              
-                loss = self.criterion(output, target)
-                
-                preds = torch.sigmoid(output['pred_output']).view(-1).detach()
-                truths = target.view(-1)
-
-                logging_outputs = {
-                    'loss': float(loss.detach().cpu()),
-                    'preds': preds,
-                    'truths': truths,
-                }
-                if self.data_parallel_world_size > 1:
-                    _logging_outputs = self._all_gather_list_sync([logging_outputs])
-
-                    for key in logging_outputs.keys():
-                        if key == 'loss':
-                            logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-                        elif key in ['preds', 'truths']:
-                            logging_outputs[key] = np.concatenate(
-                                [log[key].numpy() for log in _logging_outputs]
-                            )
-                        else:
-                            raise NotImplementedError(
-                                "What else?"
-                            )
-                    del _logging_outputs
-                else:
-                    logging_outputs['preds'] = logging_outputs['preds'].cpu().numpy()
-                    logging_outputs['truths'] = logging_outputs['truths'].cpu().numpy()
-                
-                self.metric(**logging_outputs) # iter_uddate
-
-            metric_dict = self.metric.get_epoch_dict(
-                len(data_loader)
-            )
+            self.model.eval()
+            self.criterion.eval()
 
-        log_dict = utils.log_from_dict(metric_dict, data_type, data_name, n_epoch)
+            sample = utils.prepare_sample(sample)
+            
+            _loss, sample_size, logging_output = self.criterion(self.model, sample)
 
-        if self.is_data_parallel_master and self.args.debug == False:
-            wandb.log(log_dict) 
+            logging_outputs = [logging_output]
         
-        return metric_dict
+        if self.data_parallel_world_size > 1 :
+            logging_outputs, (sample_size, ) = self._aggregate_logging_outputs(
+                logging_outputs,
+                sample_size,
+                ignore=False,
+            )
+        
+        logging_output = self._reduce_and_log_stats(dataname, logging_outputs, sample_size)
 
+        return _loss, sample_size, logging_output 
 
-    def evaluation(self, n_epoch):
-        self.model.eval()
-        break_token = False
-        stop_list = []
+    def zero_grad(self):
+        self.optimizer.zero_grad()
 
-        for data_name, dataset in self.datasets['valid'].items():
-            data_loader = self.dataloader_set(
-                dataset,
-                self.data_parallel_world_size,
-                self.args.batch_size
-            )
-            metric_dict = self.inference(data_loader, 'valid', data_name, n_epoch)
-            
-            if self.early_stopping_dict[data_name](metric_dict[self.metric.update_target]):
-                if self.is_data_parallel_master:
-                    logger.info(
-                        "Saving checkpoint to {}".format(
-                            os.path.join(self.save_dir, self.save_prefix + "_best.pt")
-                        )
-                    )
-                    best_model_path = self.save_path(self.save_dir + self.save_prefix +'_best.pt')
-                    utils.model_save(self.model, best_model_path, n_epoch, self.optimizer)
-
-            if self.early_stopping_dict[data_name].early_stop:
-                logger.info(f'data_name : {data_name}, Early stopping!')
-                stop_list.append(data_name)
-        
-        for data_name in stop_list:
-            del self.datasets['valid'][data_name]
+    def get_num_updates(self):
+        return self._num_updates
 
-        if self.datasets['valid'] == {}:
-            break_token = True
-            logger.info(f'all valid finished at {n_epoch}')
-        
-        return break_token
-        
-    def test(self, n_epoch, load_checkpoint=None):
-        print('test start .. ')
-        if load_checkpoint is not None:
-            for data_name, dataset in self.datasets['test'].items():
-
-                load_path = load_checkpoint
-                state_dict = torch.load(load_path, map_location='cpu')['model_state_dict']
-                self.model.load_state_dict(state_dict, strict = True)
-
-                data_loader = self.dataloader_set(
-                    dataset,
-                    self.data_parallel_world_size,
-                    self.args.batch_size
-                )
-                metric_dict = self.inference(
-                    data_loader, 'test', data_name, n_epoch
-                )
+    def set_num_updates(self, num_updates):
+        self._num_updates = num_updates
+        metrics.log_scalar("num_updates", self._num_updates, weight = 0, priority = 200)
+
+
+    def cumulative_training_time(self):
+        if self._cumulative_training_time is None:
+            return self._local_cumulative_training_time()
         else:
-            for data_name, dataset in self.datasets['test'].items():
-                load_path = self.save_path(data_name)+'.pkl'
-                state_dict = torch.load(load_path, map_location='cpu')['model_state_dict']
-                self.model.load_state_dict(state_dict, strict = True)
-
-                data_loader = self.dataloader_set(
-                    dataset,
-                    self.data_parallel_world_size,
-                    self.args.batch_size
-                )
-                metric_dict = self.inference(data_loader, 'test', data_name, n_epoch)
+            return self._cumulative_training_time
         
-        return metric_dict
+    def _local_cumulative_training_time(self):
+        return time.time() - self._start_time + self._previous_training_time
+
 
+    def _set_seed(self):
+        seed = self.args.seed[0] + self.get_num_updates()
+        utils.set_torch_seed(seed)
+    
+    def _sync_stats(self):
+        if self.data_parallel_world_size == 1:
+            return False
+        else:
+            return True
+
+    def _aggregate_logging_outputs(
+        self,
+        logging_outputs: List[Dict[str, Any]],
+        *extra_stats_to_sum,
+        ignore=False
+    ):
+        print(logging_outputs)
+        return self._all_gather_list_sync(
+            logging_outputs, *extra_stats_to_sum, ignore=ignore
+        )
 
     def _all_gather_list_sync(
         self,
         logging_outputs: List[Dict[str, Any]],
+        *extra_stats_to_sum,
         ignore = False
     ):
-        """
-        Sync logging outputs across workers. all_gather_list_sync is
-        suifeature when logging outputs are complex types.
-        """
+       
         if ignore:
             logging_outputs = []
         results = list(
             zip(
                 *distributed_utils.all_gather_list(
-                    [logging_outputs],
-                    max_size = getattr(self, "all_gather_list_size", 1048576),
+                    [logging_outputs] + list(extra_stats_to_sum),
+                    max_size = getattr(self, "all_gather_list_size", 16384),
                     group = self.data_parallel_process_group
                 )
             )
         )
-        logging_outputs = results[0]
+        logger.info('finish all_gahter_list')
+        logging_outputs, extra_stats_to_sum = results[0], results[1:]
         logging_outputs = list(chain.from_iterable(logging_outputs))
-        return logging_outputs
+        extra_stats_to_sum = [sum(s) for s in extra_stats_to_sum]
+        return logging_outputs, extra_stats_to_sum
+
+    def _reduce_and_log_stats(self, dataname, logging_outputs, sample_size):
+        metrics.log_speed('ups', 1.0, priority=100, round=2)
+        
+        with metrics.aggregate() as agg:
+            if logging_outputs is not None:
+                self.criterion.__class__.reduce_metrics(self.args, dataname, logging_outputs)
+                del logging_outputs
+            
+            logging_output = agg.get_smoothed_values()
+            logging_output['sample_size'] = sample_size
+            
+            return logging_output
+    
\ No newline at end of file
diff --git a/trainers/mlm_trainer.py b/trainers/mlm_trainer.py
deleted file mode 100644
index c426bcf..0000000
--- a/trainers/mlm_trainer.py
+++ /dev/null
@@ -1,529 +0,0 @@
-import os
-import torch
-import torch.nn as nn
-import wandb
-from itertools import chain
-from typing import Any, Dict, List
-import logging
-
-from metrics.metric import PredMetric, PretrainMetric
-import models
-
-import utils.trainer_utils as utils
-import utils.distributed_utils as distributed_utils
-from torch.utils.data import DataLoader, ConcatDataset
-from loss.loss import PredLoss, PretrainLoss
-from datasets.base_dataset import HierarchicalEHRDataset, UnifiedEHRDataset
-import tqdm
-
-import torch.multiprocessing as mp
-from torch.nn.parallel import DistributedDataParallel
-from torch.utils.data.distributed import DistributedSampler
-import torch.distributed as dist
-
-logger = logging.getLogger(__name__)
-
-# # trainer에서 해결해줄것
-# args.src_data = (
-#     args.src_data.split('_')
-#     if args.train_type in ['transfer', 'pooled']
-#     else args.src_data
-# )
-
-
-class MLMTranier(object):
-    def __init__(self, args, seed):
-        self.args = args
-        self.dp = args.dp
-        self.world_size = args.world_size
-
-        self.seed = seed
-        self.batch_size = args.batch_size
-        base_dir = (
-            f'src_data_{args.src_data}_icu_type_{args.icu_type}_bert_model_{args.bert_model}'
-            f'_pred_model_{args.pred_model}_type_token_{args.type_token}_dpe_{args.dpe}_lr_{args.lr}_seed_{seed}'
-        )
-        
-        pred_filename = (
-            f'text_post_proj_{args.text_post_proj}_pred_pooling_{args.pred_pooling}_map_layers_{args.map_layers}'
-            f'_n_layers_{args.n_layers}_n_heads_{args.n_heads}_embed_dim_{args.embed_dim}_pred_dim_{args.pred_dim}_dropout_{args.dropout}'
-        )
-  
-        pretrain_filename = (
-            f'mlm_prob_{args.mlm_prob}_mask_list_{" ".join(args.mask_list)}'
-        )
-
-
-        base_path = os.path.join(
-            args.output_path, 
-            args.train_task,
-            args.input2emb_model+ '_'+ args.feature
-        ) 
-
-        task_path = {
-            'predict': (
-                os.path.join(args.pred_target, args.train_type), 
-                os.path.join(base_dir, pred_filename)
-                ),
-            'pretrain': (
-                args.pretrain_task, 
-                os.path.join(base_dir, pretrain_filename)
-                )
-        }
-
-        (suffix_path, self.filename) = task_path[args.train_task]
-        
-        self.path = os.path.join(
-            base_path, 
-            suffix_path,
-            )
-
-        self.train_data = args.src_data
-      
-        self.datasets = dict() 
-        self.early_stopping_dict = dict()
-        
-        data_types = ['train'] + sorted(self.args.valid_subsets*len(self.args.eval_data))
-        data_names = [self.train_data] + self.args.eval_data*len(self.args.valid_subsets)
-        vocab = self.train_data
-        logger.info(data_types, data_names)
-
-        for split, data in zip(data_types, data_names):
-            self.load_dataset(split, data, vocab, self.seed)
-      
-        # save_directory
-        for data in args.eval_data:
-            if not os.path.exists(self.save_path(data)):
-                os.makedirs(self.save_path(data))
-
-
-    def save_path(self, data): 
-        return os.path.join(self.path, data, self.filename)  
-
-
-    def load_dataset(self, split, dataname, vocab, seed) -> None:
-        structure = 'hi' if '_' in self.args.input2emb_model else 'uni'
-        if structure == 'hi':
-            dataset = HierarchicalEHRDataset(
-                data=dataname,
-                input_path=self.args.input_path,
-                split=split,
-                vocab=vocab,
-                concept=self.args.input2emb_model,
-                column_embed=self.args.column_embed,
-                feature=self.args.feature,
-                train_task=self.args.train_task,
-                pretrain_task=self.args.pretrain_task,
-                ratio=self.args.ratio,
-                icu_type=self.args.icu_type,
-                pred_target=self.args.pred_target,
-                split_method=self.args.split_method,
-                seed=self.args.seed,
-                mask_list=self.args.mask_list,
-                mlm_prob=self.args.mlm_prob,
-                max_word_len=self.args.max_word_len,
-                max_seq_len=self.args.max_seq_len,
-            )
-        elif structure == 'uni':
-            dataset = UnifiedEHRDataset(
-                data=dataname,
-                input_path=self.args.input_path,
-                split=split,
-                vocab=vocab,
-                concept=self.args.input2emb_model,
-                column_embed=self.args.column_embed,
-                feature=self.args.feature,
-                train_task=self.args.train_task,
-                pretrain_task=self.args.pretrain_task,
-                ratio=self.args.ratio,
-                icu_type=self.args.icu_type,
-                pred_target=self.args.pred_target,
-                split_method=self.args.split_method,
-                seed=self.args.seed,
-                mask_list=self.args.mask_list,
-                mlm_prob=self.args.mlm_prob,
-                max_seq_len=self.args.max_seq_len,
-            )
-        elif  self.args.train_task=='note':
-            raise NotImplementedError
-            # dataset = NoteDataset(
-            # args=self.args,
-            # data=data,
-            # split=split,
-            # vocab=vocab,
-            # seed=seed
-            # )
-        else:
-            raise NotImplementedError
-            #datasets_list.append(_dataset)
-        #dataset = ConcatDataset(datasets_list)
-        if not split in self.datasets.keys():
-            self.datasets[split] = dict()
-
-        self.datasets[split][dataname] = dataset
-
-    def dataloader_set(self, dataset, world_size, batch_size):
-        if 1 < world_size and not self.dp:
-            sampler = DistributedSampler(dataset)
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size = batch_size, 
-                num_workers=8, 
-                sampler = sampler
-            )
-        else:
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size=batch_size,
-                num_workers=8, 
-                shuffle=True,
-                pin_memory=True,
-            )
-        return data_loader
-
-    def setup_dist(self, rank, world_size):
-        os.environ['MASTER_ADDR'] = 'localhost'
-        os.environ['MASTER_PORT'] = self.args.port
-        dist.init_process_group(
-            backend = "nccl",
-            rank = rank,
-            world_size = world_size
-        )
-        torch.cuda.set_device(rank)
-
-        if torch.cuda.is_available():
-            dist.all_reduce(torch.zeros(1).cuda())
-
-    @property
-    def data_parallel_world_size(self):
-        if self.args.world_size == 1 or self.dp:
-            return 1
-        return distributed_utils.get_data_parallel_world_size()
-    
-    @property
-    def data_parallel_process_group(self):
-        return distributed_utils.get_data_parallel_group()
-    
-    @property
-    def data_parallel_rank(self):
-        if self.args.world_size == 1 or self.dp:
-            return 0
-        return distributed_utils.get_data_parallel_rank()
-    
-    @property
-    def is_data_parallel_master(self):
-        return self.data_parallel_rank == 0
-
-    def train(self):
-        if 1 < self.args.world_size and not self.dp:
-            mp.spawn(self.distributed_train,
-                    args=(self.args.world_size,),
-                    nprocs=self.args.world_size,
-                    join=True)
-        else:
-            self.distributed_train(self.args.device_num, self.args.world_size)
-        
-    def distributed_train(self, rank, world_size):
-        if 1 < world_size and not self.dp:
-            self.setup_dist(rank, world_size)
-        
-        # wandb
-        if not self.args.debug and (not self.dp or self.is_data_parallel_master):
-            wandb.init(
-                project=self.args.wandb_project_name,
-                entity="kaggle-wandb",
-                config=self.args,
-                reinit=True
-            )
-            wandb.run.name = self.args.wandb_run_name
-
-        model = models.build_model(self.args)
-         #resume code 
-        
-        #transfer
-        if self.args.train_type =='transfer':
-            load_path = self.save_path(self.args.src_data).replace('transfer', 'single')
-            print('transfer learning, load model from : ', load_path)
-            state_dict = torch.load()['model_state_dict']
-            model.load_state_dict(state_dict, strict = False)
-            self.train_data = self.args.eval_data # finetune train data
-
-        #num_params = count_parameters(model) 
-        # print(
-        #     'Model build :' , 
-        #     'Number of parameters: ', num_params
-        # )
-
-        if 1 < world_size and not self.dp:
-            device = torch.device(f"cuda:{rank}" if torch.cuda.is_available() else "cpu")
-            self.model = model.to(device)
-            self.model = DistributedDataParallel(self.model, device_ids = [rank], find_unused_parameters=False)
-        else:       
-            self.model = nn.DataParallel(model, device_ids=self.args.device_ids).to('cuda')
-
-        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)
-       
-        load_dict= None
-        load_path = self.save_path(self.args.eval_data[0]) + '.pkl'
-        print('load target path : ', load_path)
-        if os.path.exists(load_path):
-            print('resume training start ! load checkpoint from : ', load_path)
-            load_dict = torch.load(load_path, map_location='cpu')
-            model_state_dict = load_dict['model_state_dict']
-            optimizer_state_dict = load_dict['optimizer_state_dict']
-
-            self.model.load_state_dict(model_state_dict, strict = True)
-            self.optimizer.load_state_dict(optimizer_state_dict)
-        else:
-            print('training from scratch start !')   
-
-        data_loader = self.dataloader_set(
-                    self.datasets['train'][self.train_data], 
-                    world_size,  
-                    self.args.batch_size
-        )
-
-        Loss = PredLoss if self.args.train_task =='predict' else PretrainLoss
-        self.criterion = Loss(self.args)
-        metric = PredMetric if self.args.train_task =='predict' else PretrainMetric
-        self.metric = metric(self.args)
-
-        for data in self.datasets['valid'].keys(): 
-            self.early_stopping_dict[data] = utils.EarlyStopping(
-                patience=self.args.patience, 
-                compare=self.metric.compare,
-                metric=self.metric.update_target
-            )
-            
-        start_epoch = load_dict['n_epoch'] if load_dict is not None else 1
-        for n_epoch in range(start_epoch, self.args.epochs + 1):
-            logger.info('[Epoch] {}'.format(n_epoch))
-            self.model.train()
-            
-            for iter, sample in tqdm.tqdm(enumerate(data_loader)):
-           
-                self.optimizer.zero_grad(set_to_none=True)
-                output = self.model(**sample['net_input'])
-                target = self.model.module.get_targets(sample)
-                
-                for victim in self.args.mask_list:
-                    target[victim+'_label'] = torch.where(
-                        target[victim+'_label'] == 0, -100, target[victim+'_label']
-                    )
-
-                loss = self.criterion(output, target)
-                loss.backward()
-                
-                self.optimizer.step()
-
-                logging_outputs = {
-                    'loss': loss.detach().cpu()
-                }
-                for victim in self.args.mask_list:
-                    preds = torch.argmax(output[victim+'_ids'], dim=2).view(-1).detach().cpu()
-                    target_label = target[victim+'_label'].view(-1)
-                    mask_idcs = (target_label != -100) & (target_label != 0)
-                    total = mask_idcs.sum()
-                    correct = (preds[mask_idcs] == target_label[mask_idcs]).sum().float()
-
-                    logging_outputs[victim+'_ids_correct'] = correct
-                    logging_outputs[victim+'_ids_total'] = total
-                # logging_outputs['total'] = total
-
-                if self.world_size > 1 and not self.dp:
-                    _logging_outputs = self._all_gather_list_sync([logging_outputs])
-
-                    for key in logging_outputs.keys():
-                        logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-
-                        if 'loss' in key:
-                            logging_outputs[key] /= len(_logging_outputs)
-                        else:
-                            logging_outputs[key] = int(logging_outputs[key])
-
-                    del _logging_outputs
-
-                logging_outputs['total'] = {
-                    victim+'_ids': logging_outputs.pop(victim+'_ids_total')
-                    for victim in self.args.mask_list
-                }
-                logging_outputs['correct'] = {
-                    victim+'_ids': logging_outputs.pop(victim+'_ids_correct')
-                    for victim in self.args.mask_list
-                }
-                self.metric(**logging_outputs) # iter_uddate
-
-            with torch.no_grad():
-                train_metric_dict = self.metric.get_epoch_dict(
-                    len(data_loader)
-                )
-    
-            log_dict = utils.log_from_dict(train_metric_dict, 'train', self.train_data, n_epoch)
-            
-            if not self.args.debug and (not self.dp or self.is_data_parallel_master):
-                wandb.log(log_dict) 
-            
-            break_token = self.evaluation(n_epoch)
-      
-            if break_token:
-                break
-            
-        self.final_epoch = n_epoch
-        print(f'train finished at epoch {n_epoch}')
-
-        if self.is_data_parallel_master and self.args.debug == False:
-            wandb.finish(0)
-
-        if self.world_size > 1 and not self.dp:
-            dist.destroy_process_group()
-
-    def inference(self, data_loader, data_type, data_name, n_epoch):
-        self.model.eval()
-        with torch.no_grad():
-            for iter, sample in tqdm.tqdm(enumerate(data_loader)):
-                self.optimizer.zero_grad(set_to_none=True)
-           
-                output = self.model(**sample['net_input'])
-                target = self.model.module.get_targets(sample)
-            
-                loss = self.criterion(output, target)
-                
-                logging_outputs = {
-                    'loss': loss.detach().cpu()
-                }
-                for victim in self.args.mask_list:
-                    preds = torch.argmax(output[victim+'_ids'], dim=2).view(-1).detach().cpu()
-                    target_label = target[victim+'_label'].view(-1)
-                    mask_idcs = (target_label != -100) & (target_label != 0)
-                    total = mask_idcs.sum()
-                    correct = (preds[mask_idcs] == target_label[mask_idcs]).sum().float()
-
-                    logging_outputs[victim+'_ids_correct'] = correct
-                    logging_outputs[victim+'_ids_total'] = total
-                # logging_outputs['total'] = total
-
-                if self.world_size > 1 and not self.dp:
-                    _logging_outputs = self._all_gather_list_sync([logging_outputs])
-
-                    for key in logging_outputs.keys():
-                        logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-
-                        if 'loss' in key:
-                            logging_outputs[key] /= len(_logging_outputs)
-                        else:
-                            logging_outputs[key] = int(logging_outputs[key])
-
-                    del _logging_outputs
-
-                logging_outputs['total'] = {
-                    victim+'_ids': logging_outputs.pop(victim+'_ids_total')
-                    for victim in self.args.mask_list
-                }
-                logging_outputs['correct'] = {
-                    victim+'_ids': logging_outputs.pop(victim+'_ids_correct')
-                    for victim in self.args.mask_list
-                }
-                self.metric(**logging_outputs) # iter_uddate
-
-            metric_dict = self.metric.get_epoch_dict(
-                len(data_loader)
-            )
-
-        log_dict = utils.log_from_dict(metric_dict, data_type, data_name, n_epoch)
-
-        if not self.args.debug and (not self.dp or self.is_data_parallel_master):
-            wandb.log(log_dict) 
-        
-        return metric_dict
-
-
-    def evaluation(self, n_epoch):
-        self.model.eval()
-        break_token = False
-            
-        for data_name, dataset in self.datasets['valid'].items():
-            data_loader = self.dataloader_set(
-                dataset, 
-                self.world_size,
-                self.args.batch_size
-            )
-            metric_dict = self.inference(data_loader, 'valid', data_name, n_epoch)
-
-            if self.early_stopping_dict[data_name](metric_dict[self.metric.update_target]):
-                if not self.dp or self.is_data_parallel_master:
-                    best_model_path = self.save_path(data_name)
-                    utils.model_save(self.model, best_model_path, n_epoch, self.optimizer)
-
-            if self.early_stopping_dict[data_name].early_stop:
-                logger.info(f'data_name : {data_name}, Early stopping!')
-                del self.datasets['valid'][data_name]
-
-        if self.datasets['valid'] == {}:
-            break_token = True
-            logger.info(f'all valid finished at {n_epoch}')
-    
-        return break_token
-  
-
-  # pooled 일때 test 손 봐야함.
-
-    def test(self, load_checkpoint=None):
-        print('test start .. ')  
-        
-        #state_dict = {k.replace('module.',''): state_dict[k] for k in state_dict if (not 'embedding' in k and not 'bert_embed' in k)}
-        if load_checkpoint is not None:
-            load_path = load_checkpoint
-            state_dict = torch.load(load_path, map_location='cpu')['model_state_dict']
-            self.model.load_state_dict(state_dict, strict = False)
-            data_loader = self.dataloader_set(
-                self.datasets['test'],
-                1, 
-                self.args.batch_size
-            )
-
-            metric_dict = self.inference(
-            data_loader, 'test', data_name, self.final_epoch
-            )
-            
-           
-        else:
-            for data_name, dataset in self.datasets['test']:
-                load_path = self.save_path(data_name)
-
-                state_dict = torch.load(load_path, map_location='cpu')['model_state_dict']
-                self.model.load_state_dict(state_dict, strict = False)
-                data_loader = self.dataloader_set(
-                    dataset, 
-                    1, 
-                    self.args.batch_size
-                )
-
-                metric_dict = self.inference(
-                data_loader, 'test', data_name, self.final_epoch
-                )
-    
-    def _all_gather_list_sync(
-        self,
-        logging_outputs: List[Dict[str, Any]],
-        ignore = False
-    ):
-        """
-        Sync logging outputs across workers. all_gather_list_sync is
-        suifeature when logging outputs are complex types.
-        """
-        if ignore:
-            logging_outputs = []
-        results = list(
-            zip(
-                *distributed_utils.all_gather_list(
-                    [logging_outputs],
-                    max_size = getattr(self, "all_gather_list_size", 65536),
-                    group = self.data_parallel_process_group
-                )
-            )
-        )
-        logging_outputs = results[0]
-        logging_outputs = list(chain.from_iterable(logging_outputs))
-        return logging_outputs
diff --git a/trainers/w2v_trainer.py b/trainers/w2v_trainer.py
deleted file mode 100644
index 6c8f1f1..0000000
--- a/trainers/w2v_trainer.py
+++ /dev/null
@@ -1,566 +0,0 @@
-import os
-import logging
-import math
-from itertools import chain
-from typing import Any, Dict, List
-import wandb
-
-import torch
-import torch.nn as nn
-from torch.utils.data import DataLoader
-
-from utils import utils
-import utils.trainer_utils as tr_utils
-import utils.distributed_utils as dist_utils
-from datasets.base_dataset import HierarchicalEHRDataset, UnifiedEHRDataset
-from metrics.metric import W2VMetric
-
-import models
-
-import torch.multiprocessing as mp
-from torch.nn.parallel import DistributedDataParallel
-from torch.utils.data.distributed import DistributedSampler
-import torch.distributed as dist
-
-from tqdm import tqdm
-
-logger = logging.getLogger(__name__)
-
-class W2VTrainer(object):
-    def __init__(self, args, seed):
-        self.args = args
-        
-        self.seed = seed
-        self.batch_size = args.batch_size
-
-        self.loss_weights = [0.1, 5]
-        self.max_loss_weights = [0.1, 5]
-        self.min_loss_weights = [0.005, 0.25]
-        self.log_interval = 25
-        self.epoch_save_interval = 50
-        self.epoch_validate_from = 10
-        self.no_validation = True
-
-        self.args.loss_weights = self.loss_weights
-
-        self.codebook_negatives = args.codebook_negatives
-
-        base_dir = (
-            f'src_data_{args.src_data}_icu_type_{args.icu_type}_bert_model_{args.bert_model}'
-            f'_pred_model_{args.pred_model}_type_token_{args.type_token}_dpe_{args.dpe}_lr_{args.lr}_seed_{seed}'
-        )
-        
-        pred_filename = (
-            f'text_post_proj_{args.text_post_proj}_pred_pooling_{args.pred_pooling}_map_layers_{args.map_layers}'
-            f'_n_layers_{args.n_layers}_n_heads_{args.n_heads}_embed_dim_{args.embed_dim}_pred_dim_{args.pred_dim}_dropout_{args.dropout}'
-        )
-  
-        pretrain_filename = (
-            f'{str(self.loss_weights[0])}_{str(self.loss_weights[1])}'
-        )
-
-        base_path = os.path.join(
-            args.output_path, 
-            args.train_task,
-            args.input2emb_model+ '_'+ args.feature
-        )
-
-        task_path = {
-            'predict': (
-                os.path.join(args.pred_target, args.train_type), 
-                os.path.join(base_dir, pred_filename)
-                ),
-            'pretrain': (
-                args.pretrain_task, 
-                os.path.join(base_dir, pretrain_filename)
-                )
-        }
-
-        (suffix_path, self.filename) = task_path[args.train_task]
-
-        self.path = os.path.join(
-            base_path, 
-            suffix_path,
-        )
-
-        self.train_data = args.src_data
-      
-        self.datasets = dict() 
-        self.early_stopping_dict = dict()
-
-        vocab = self.train_data
-
-        self.datasets['train'] = self.load_dataset(split='train', vocab=vocab, seed=seed)
-        for v in args.valid_subsets:
-            self.datasets[v] = self.load_dataset(split=v, vocab=vocab, seed=seed)
-
-        # save_directory
-        for data in args.eval_data:
-            rindex = self.save_path(data).rfind('/')
-            if not os.path.exists(self.save_path(data)[:rindex]):
-                os.makedirs(self.save_path(data)[:rindex])
-
-        # self.save_dir = os.path.join(
-        #     args.output_path, 'w2v', args.input2emb_model, args.feature
-        # )
-        # if not os.path.exists(self.save_dir):
-        #     os.makedirs(self.save_dir)
-
-    def save_path(self, data): 
-        return os.path.join(self.path, data, self.filename) 
-    
-    def load_dataset(self, split, vocab, seed):
-        structure = 'hi' if '_' in self.args.input2emb_model else 'uni'
-        if structure =='hi':
-            dataset = HierarchicalEHRDataset(
-                data=self.args.src_data,
-                input_path=self.args.input_path,
-                split=split,
-                vocab=vocab,
-                concept=self.args.input2emb_model,
-                column_embed=self.args.column_embed,
-                feature=self.args.feature,
-                train_task=self.args.train_task,
-                pretrain_task=self.args.pretrain_task,
-                ratio=self.args.ratio,
-                icu_type=self.args.icu_type,
-                pred_target=self.args.pred_target,
-                split_method=self.args.split_method,
-                seed=self.args.seed,
-                mask_list=self.args.mask_list,
-                mlm_prob=self.args.mlm_prob,
-                max_word_len=self.args.max_word_len,
-                max_seq_len=self.args.max_seq_len,
-            )
-        else:
-            raise AttributeError(
-                'pre-train w2v requires the structure of EHR to be hierarchical. '
-                'current structure: {}'.format(structure)
-            )
-        
-        return dataset
-
-    def dataloader_set(self, dataset, world_size, batch_size):
-        if 1 < world_size:
-            sampler = DistributedSampler(dataset)
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size = batch_size, 
-                num_workers=8, 
-                sampler = sampler
-            )
-        else:
-            data_loader = DataLoader(
-                dataset, 
-                collate_fn=dataset.collator,
-                batch_size=batch_size,
-                num_workers=8, 
-                shuffle=True,
-                pin_memory=True,
-            )
-        return data_loader
-
-    def setup_dist(self, rank, world_size):
-        os.environ['MASTER_ADDR'] = 'localhost'
-        os.environ['MASTER_PORT'] = self.args.port
-        dist.init_process_group(
-            backend = "nccl",
-            rank = rank,
-            world_size = world_size
-        )
-        torch.cuda.set_device(rank)
-
-        if torch.cuda.is_available():
-            dist.all_reduce(torch.zeros(1).cuda())
-
-    @property
-    def data_parallel_world_size(self):
-        if self.args.world_size == 1:
-            return 1
-        return dist_utils.get_data_parallel_world_size()
-    
-    @property
-    def data_parallel_process_group(self):
-        return dist_utils.get_data_parallel_group()
-    
-    @property
-    def data_parallel_rank(self):
-        if self.args.world_size == 1:
-            return 0
-        return dist_utils.get_data_parallel_rank()
-    
-    @property
-    def is_data_parallel_master(self):
-        return self.data_parallel_rank == 0
-
-    def train(self):
-        if 1 < self.args.world_size:
-            mp.spawn(self.distributed_train,
-                    args=(self.args.world_size,),
-                    nprocs=self.args.world_size,
-                    join=True)
-        else:
-            self.distributed_train(self.args.device_num, self.args.world_size)
-    
-    def distributed_train(self, rank, world_size):
-        if 1 < world_size:
-            self.setup_dist(rank, world_size)
-
-        # wandb
-        if not self.args.debug and self.is_data_parallel_master:
-            wandb.init(
-                project=self.args.wandb_project_name,
-                entity="kaggle-wandb",
-                config=self.args,
-                reinit=True
-            )
-            wandb.run.name = self.args.wandb_run_name
-
-        model = models.build_model(self.args)
-    
-
-        if 1 < world_size:
-            device = torch.device(f"cuda:{rank}" if torch.cuda.is_available() else "cpu")
-            self.model = model.to(device)
-            self.model = DistributedDataParallel(self.model, device_ids = [rank], find_unused_parameters=False)
-        else:
-            self.model = nn.DataParallel(model, device_ids=self.args.device_ids).to('cuda')
-
-        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=0.01)
-
-        start_epoch = 0
-        if self.args.resume:
-            resume_path = self.save_path(self.args.eval_data[0])
-            logger.info('resume training from {}'.format(resume_path))
-
-            state_dict = torch.load(resume_path+'.pkl', 'cpu')
-            start_epoch = state_dict['n_epoch']
-            self.model.load_state_dict(state_dict['model_state_dict'], strict=True)
-            self.optimizer.load_state_dict(state_dict['optimizer_state_dict'])
-
-            del state_dict
-
-        data_loader = self.dataloader_set(
-            self.datasets['train'], 
-            world_size,  
-            self.args.batch_size
-        )
-
-        self.criterion = nn.CrossEntropyLoss(reduction='sum')
-        self.metric = W2VMetric(target='acc')
-
-        for v in self.args.valid_subsets:
-            if 'valid' in v:
-                if not self.early_stopping_dict:
-                    self.early_stopping_dict[v] = tr_utils.EarlyStopping(
-                        patience=self.args.patience,
-                        compare=self.metric.compare,
-                        metric=self.metric.update_target
-                    )
-                else:
-                    raise AttributeError(
-                        "please ensure that there are only one valid subset in --valid_subsets. "
-                        "--valid_subsets: {}".format(self.args.valid_subsets)
-                    )
-
-        inner_metric = W2VMetric()
-        for n_epoch in range(start_epoch, self.args.epochs + 1):
-            self.model.train()
-            inner_metric.reset()
-
-            with tqdm(total=len(data_loader)) as pbar:
-                for i, sample in enumerate(data_loader):
-                    sample = self._prepare_sample(sample)
-
-                    self.optimizer.zero_grad(set_to_none=True)
-
-                    # #####################################
-                    # state_dict = torch.load('/home/edlab/ghhur/Pretrained_DescEmb/data/output/pretrain/descemb_bert_whole/w2v/eicu/src_data_eicu_icu_type_ticu_bert_model_bert_tiny_pred_model_transformer_type_token_True_dpe_True_lr_5e-05_seed_2020/mlm_prob_0.3_mask_list_input type.pkl', 'cpu')
-                    # self.model.load_state_dict(state_dict['model_state_dict'])
-                    # with torch.no_grad():
-                    #     net_output = self.model(**sample['net_input'])
-                    #     breakpoint()
-                    #     print()
-                    # ########################################
-                    net_output = self.model(**sample['net_input'])
-
-                    logits = self.model.module.get_logits(net_output)
-                    targets = self.model.module.get_targets(sample, net_output)
-
-                    loss = self.criterion(logits, targets)
-
-                    losses = [loss.detach().clone()]
-
-                    sample_size = targets.numel()
-
-                    extra_losses = self.model.module.get_extra_losses(net_output)
-                    if torch.is_tensor(extra_losses):
-                        extra_losses = [extra_losses]
-                    for p, coef in zip(extra_losses, self.loss_weights):
-                        if coef == 0:
-                            losses.append(torch.tensor(0))
-                        elif p is not None:
-                            p = coef * p.float() * sample_size
-                            loss += p
-                            losses.append(p)
-
-                    loss.backward()
-                    self.optimizer.step()
-                    # scheduler.step()
-
-
-                    num_updates = 1 + i + n_epoch * len(data_loader)
-                    self.model.module.set_num_updates(num_updates)
-                    # for j in range(len(self.loss_weights)):
-                    #     self.loss_weights[j] = max(
-                    #         self.max_loss_weights[j] * 0.9995 ** num_updates, self.min_loss_weights[j]
-                    #     )
-
-                    logging_outputs = {
-                        'loss_0': losses[0].item() / sample_size / math.log(2),
-                        'loss_1': losses[1].item() / sample_size / math.log(2),
-                        'loss_2': losses[2].item() / sample_size / math.log(2),
-                        'prob_ppl': net_output['prob_perplexity'].item(),
-                        'code_ppl': net_output['code_perplexity'].item(),
-                    }
-
-                    with torch.no_grad():
-                        if logits.numel() == 0:
-                            corr = 0
-                            count = 0
-                        else:
-                            assert logits.dim() > 1, logits.shape
-                            _max = logits.argmax(-1) == 0
-                            _min = logits.argmin(-1) == 0
-
-                            both = _max & _min
-                            corr = _max.long().sum().item() - both.long().sum().item()
-                            count = float(_max.numel())
-                        
-                        logging_outputs['correct'] = corr
-                        logging_outputs['total'] = count
-                    
-                    if self.data_parallel_world_size > 1:
-                        _logging_outputs = self._all_gather_list_sync([logging_outputs])
-                        for key in logging_outputs.keys():
-                            logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-
-                            if 'loss' in key or 'ppl':
-                                logging_outputs[key] = (
-                                    logging_outputs[key] / len(_logging_outputs)
-                                )
-                            else:
-                                logging_outputs[key] = int(logging_outputs[key])
-                        del _logging_outputs
-                    
-                    self.metric.update(**logging_outputs)
-                    inner_metric.update(**logging_outputs)
-
-                    pbar.set_postfix_str(
-                        f'[Epoch {n_epoch + 1}] loss_0: {losses[0].item() / sample_size / math.log(2):.3f}, '
-                        f'loss_1: {losses[1].item() / sample_size / math.log(2):.4f}, '
-                        f'loss_2: {losses[2].item() / sample_size / math.log(2):.3f}, '
-                        f'acc: {corr / count:.4f}'
-                    )
-                    pbar.update(1)
-
-                    if (i + 1) % self.log_interval == 0:
-                        mid_stats = inner_metric.get_epoch_dict(
-                            total_iter=self.log_interval
-                        )
-
-                        # with torch.no_grad():
-                        #     q = self.model.module.quantize(**sample['net_input'])
-
-                        # print(
-                        #     f'[{i+1}] loss_0: {mid_stats["loss_0"]:.3f}, '
-                        #     f'loss_1: {mid_stats["loss_1"]:.5f}, '
-                        #     f'loss_2: {mid_stats["loss_2"]:.5f}, '
-                        #     f'acc: {mid_stats["acc"]:.3f}\n'
-                        #     f'[{i+1}] n_code: {q[1][net_output["mask_indices"]].unique().numel()}, '
-                        #     f'prob: {mid_stats["prob_ppl"]:.3f}, '
-                        #     f'code: {mid_stats["code_ppl"]:.3f}, '
-                        #     f'temp: {net_output["temp"]:.3f}, '
-                        #     f'w1: {self.loss_weights[0]:.3f}, w2: {self.loss_weights[1]:.3f}'
-                        # )
-                        # with torch.no_grad():
-                        #     self.model.eval()
-                            # k = self.model.module.extract_features(**sample['net_input'])
-                            # p = k['features'][net_output['mask_indices']]
-                            # mask_q = self.model.module.quantizer.forward_idx(p.view(k['features'].size(0), -1, k['features'].size(-1)))
-                            # keep_q = self.model.module.quantizer.forward_idx(keep_features)
-                            # self.model.train()
-                            # breakpoint()
-                            # pass
-                        if self.is_data_parallel_master and not self.args.debug:
-                            prefix = 'train_inner/'
-                            for key in mid_stats.keys():
-                                wandb.log({prefix + key: mid_stats[key]}, step=(i+1) + n_epoch*len(data_loader))
-                            del mid_stats
- 
-            train_stats = self.metric.get_epoch_dict(
-                total_iter = len(data_loader)
-            )
-
-            train_stats['epoch'] = n_epoch
-            if self.is_data_parallel_master and self.args.debug == False:
-                prefix = 'train/'
-                for key in train_stats.keys():
-                    wandb.log({prefix + key: train_stats[key]})
-
-            if not self.no_validation and (n_epoch + 1) >= self.epoch_validate_from:
-                valid_stats, early_stop = self.validate(n_epoch)
-                if self.is_data_parallel_master and self.args.debug == False:
-                    prefix = 'valid/'
-                    for key in valid_stats.keys():
-                        wandb.log({prefix + key: valid_stats[key]})
-                
-                if early_stop:
-                    logger.info(
-                        'early stop since valid performance has not improved for '
-                        'last {} runs'.format(self.args.patience)
-                    )
-                    break
-            
-            if (n_epoch + 1) % self.epoch_save_interval == 0:
-                if self.is_data_parallel_master:
-                    best_model_path = self.save_path(self.args.eval_data[0]) + '_last'
-                    tr_utils.model_save(self.model, best_model_path, n_epoch, self.optimizer)
-
-        logger.info('train finished at epoch {}'.format(n_epoch))
-
-        if self.is_data_parallel_master and self.args.debug == False:
-            wandb.finish(0)
-
-        if world_size > 1:
-            dist.destroy_process_group()
-
-    @torch.no_grad()
-    def validate(self, n_epoch, subset='valid'):
-        data_loader = self.dataloader_set(
-            self.datasets[subset],
-            self.data_parallel_world_size,
-            self.args.batch_size
-        )
-        self.model.eval()
-        with tqdm(total=len(data_loader)) as pbar:
-            for sample in data_loader:
-                sample = self._prepare_sample(sample)
-
-                net_output = self.model(**sample['net_input'])
-
-                logits = self.model.module.get_logits(net_output)
-                targets = self.model.module.get_targets(sample, net_output)
-
-                loss = self.criterion(logits, targets)
-
-                losses = [loss.detach().clone()]
-
-                sample_size = targets.numel()
-
-                extra_losses = self.model.module.get_extra_losses(net_output)
-                if torch.is_tensor(extra_losses):
-                    extra_losses = [extra_losses]
-                for p, coef in zip(extra_losses, self.loss_weights):
-                    if coef != 0 and p is not None:
-                        p = coef * p.float() * sample_size
-                        loss += p
-                        losses.append(p)
-
-                logging_outputs = {
-                    'loss_0': losses[0].item() / sample_size / math.log(2),
-                    'loss_1': losses[1].item() / sample_size / math.log(2),
-                    'loss_2': losses[2].item() / sample_size / math.log(2),
-                    'prob_ppl': net_output['prob_perplexity'].item(),
-                    'code_ppl': net_output['code_perplexity'].item(),
-                }
-
-                with torch.no_grad():
-                    if logits.numel() == 0:
-                        corr = 0
-                        count = 0
-                    else:
-                        assert logits.dim() > 1, logits.shape
-                        _max = logits.argmax(-1) == 0
-                        _min = logits.argmin(-1) == 0
-
-                        both = _max & _min
-                        corr = _max.long().sum().item() - both.long().sum().item()
-                        count = float(_max.numel())
-                    
-                    logging_outputs['correct'] = corr
-                    logging_outputs['total'] = count
-                
-                if self.data_parallel_world_size > 1:
-                    _logging_outputs = self._all_gather_list_sync([logging_outputs])
-                    for key in logging_outputs.keys():
-                        logging_outputs[key] = float(sum(log[key] for log in _logging_outputs))
-
-                        if 'loss' in key or 'ppl':
-                            logging_outputs[key] = (
-                                logging_outputs[key] / len(_logging_outputs)
-                            )
-                        else:
-                            logging_outputs[key] = int(logging_outputs[key])
-                    del _logging_outputs
-
-
-                self.metric.update(**logging_outputs)
-
-                pbar.set_postfix_str(
-                    f'[Epoch {n_epoch + 1}] loss_0: {losses[0].item() / sample_size / math.log(2):.3f}, '
-                    f'loss_1: {losses[1].item() / sample_size / math.log(2):.4f}, '
-                    f'loss_2: {losses[2].item() / sample_size / math.log(2):.3f}, '
-                    f'acc: {corr / count:.4f}'
-                )
-                pbar.update(1)
-        
-        valid_stats = self.metric.get_epoch_dict(
-            total_iter=len(data_loader)
-        )
-        valid_stats['epoch'] = n_epoch
-
-        if self.early_stopping_dict[subset](valid_stats[self.metric.update_target]):
-            if self.is_data_parallel_master:
-                # best_model_path = os.path.join(
-                #     self.save_dir, f'{self.seed}_pretrained_{self.args.pretrained_load}'
-                # )
-                best_model_path = self.save_path(self.args.eval_data[0])
-                tr_utils.model_save(self.model, best_model_path, n_epoch, self.optimizer)
-
-        stopped = False
-        if self.early_stopping_dict[subset].early_stop:
-            stopped = True
-        
-        return valid_stats, stopped
-
-    def _all_gather_list_sync(
-        self,
-        logging_outputs: List[Dict[str, Any]],
-        ignore = False
-    ):
-        """
-        Sync logging outputs across workers. all_gather_list_sync is
-        suifeature when logging outputs are complex types.
-        """
-        if ignore:
-            logging_outputs = []
-        results = list(
-            zip(
-                *dist_utils.all_gather_list(
-                    [logging_outputs],
-                    max_size = getattr(self, "all_gather_list_size", 1048576),
-                    group = self.data_parallel_process_group
-                )
-            )
-        )
-        logging_outputs = results[0]
-        logging_outputs = list(chain.from_iterable(logging_outputs))
-        return logging_outputs
-    
-    def _prepare_sample(self, sample):
-        if torch.cuda.is_available():
-            sample = utils.move_to_cuda(sample)
-        
-        return sample
\ No newline at end of file
diff --git a/utils/data_utils.py b/utils/data_utils.py
old mode 100644
new mode 100755
diff --git a/utils/distributed_utils.py b/utils/distributed_utils.py
old mode 100644
new mode 100755
index 9d3535e..c9fb232
--- a/utils/distributed_utils.py
+++ b/utils/distributed_utils.py
@@ -1,11 +1,19 @@
-import pickle
+import logging
+import os
+import random
+import socket
 import struct
-from collections import OrderedDict
-from typing import Any, Dict, List, Mapping, Optional
+import pickle
+import warnings
 
 import torch
 import torch.distributed as dist
 
+logger = logging.getLogger(__name__)
+
+def is_master(args):
+    return args.distributed_rank == 0
+
 def get_rank(group):
     return dist.get_rank(group=group)
 
@@ -49,32 +57,63 @@ def get_data_parallel_world_size():
     """Return world size for the data parallel group."""
     return get_world_size(get_data_parallel_group())
 
-def all_reduce(tensor, group, op='sum'):
-    if op == 'sum':
+def infer_init_method(args):
+    assert (
+        args.world_size <= torch.cuda.device_count()
+    ), f"world size is {args.world_size} but have {torch.cuda.device_count()} available devices"
+    port = random.randint(10000, 20000)
+    args.distributed_init_method = "tcp://localhost:{port}".format(port=port)
+
+def distributed_init(args):
+    if dist.is_available() and dist.is_initialized():
+        warnings.warn(
+            'Distributed is already initialized'
+        )
+    else:
+        logger.info(
+            'distributed init (rank {}): {}'.format(
+                args.distributed_rank,
+                args.distributed_init_method
+            )
+        )
+        dist.init_process_group(
+            backend='nccl',
+            init_method=args.distributed_init_method,
+            world_size=args.world_size,
+            rank=args.distributed_rank
+        )
+        logger.info(
+            'initialized host {} as rank {}'.format(
+                socket.gethostname(),
+                args.distributed_rank
+            )
+        )
+
+        #perform a dummy all-reduce to initialize the NCCL communicator
+        if torch.cuda.is_available():
+            dist.all_reduce(torch.zeros(1).cuda())
+
+    args.distributed_rank = dist.get_rank()
+
+    if is_master(args):
+        logging.getLogger().setLevel(logging.INFO)
+    else:
+        logging.getLogger().setLevel(logging.WARNING)
+
+    return args.distributed_rank
+
+def all_reduce(tensor, group, op = "sum"):
+    if op == "sum":
         op = dist.ReduceOp.SUM
-    elif op == 'max':
+    elif op == "max":
         op = dist.ReduceOp.MAX
     else:
         raise NotImplementedError
-    dist.all_reduce(tensor, op=op, group=group)
+    
+    dist.all_reduce(tensor, op = op, group = group)
+    
     return tensor
 
-def broadcast(tensor, src, group):
-    dist.broadcast(tensor, src = src, group = group)
-
-def all_gather(tensor, group, return_tensor = False):
-    """Perform an all-gather operation."""
-    world_size = get_world_size(group = group)
-    rank = get_rank(group = group)
-    tensor_list = [
-        tensor if i == rank else torch.empty_like(tensor) for i in range(world_size)
-    ]
-    dist.all_gather(tensor_list, tensor, group = group)
-    if return_tensor:
-        return torch.stack(tensor_list, dim = 0)
-    else:
-        return tensor_list
-
 def all_gather_list(data, group = None, max_size = 16384):
     """Gathers arbitrary data from all nodes into a list.
 
@@ -88,7 +127,7 @@ def all_gather_list(data, group = None, max_size = 16384):
         max_size (int, optional): maximum size of the data to be gathered
             across workers
     """
-    from utils import utils
+    import utils.utils as utils
 
     if group is None:
         group = get_global_group()
@@ -120,7 +159,7 @@ def all_gather_list(data, group = None, max_size = 16384):
     cpu_buffer[:size] = torch.ByteTensor(list(header + enc))
     start = rank * max_size
     buffer[start : start + size].copy_(cpu_buffer[:size])
-
+    
     all_reduce(buffer, group = group)
 
     buffer = buffer.cpu()
@@ -147,51 +186,83 @@ def all_gather_list(data, group = None, max_size = 16384):
             # "Try rerunning with --ddp-backend=legacy_ddp and see if that helps."
         )
 
-def all_reduce_dict(data: Mapping[str, Any], device, group) -> Dict[str, Any]:
-    """
-    AllReduce a dictionary of values across workers. We separately
-    reduce items that are already on the device and items on CPU for
-    better performance.
-
-    Args:
-        data (Mapping[str, Any]): dictionary of data to all-reduce, but
-            cannot be a nested dictionary
-        device (torch.device): device for the reduction
-        group: group of the collective
-    """
-    data_keys = list(data.keys())
-
-    # We want to separately reduce items that are already on the
-    # device and items on CPU for performance reasons.
-    cpu_data = OrderedDict()
-    device_data = OrderedDict()
-    for k in data_keys:
-        t = data[k]
-        if not torch.is_tensor(t):
-            cpu_data[k] = torch.tensor(t, dtype = torch.double)
-        elif t.device.type != device.type:
-            cpu_data[k] = t.to(dtype = torch.double)
-        else:
-            device_data[k] = t.to(dtype = torch.double)
-    
-    def _all_reduce_dict(data: OrderedDict):
-        if len(data) == 0:
-            return data
-        
-        buf = torch.cat([t.view(-1) for t in data.values()]).to(device = device)
-        all_reduce(buf, group = group)
-        split_buf = torch.split(buf, [t.numel() for t in data.values()])
-        reduced_data = [t.view_as(orig) for t, orig in zip(split_buf, data.values())]
-        return OrderedDict(zip(data.keys(), reduced_data))
+def distributed_main(i, main, args, kwargs):
+    args.device_id = i
+    if torch.cuda.is_available():
+        torch.cuda.set_device(i)
+    if args.distributed_rank is None:
+        args.distributed_rank = i
     
-    cpu_data = _all_reduce_dict(cpu_data)
-    device_data = _all_reduce_dict(device_data)
-
-    def get_from_stack(key):
-        if key in cpu_data:
-            return cpu_data[key]
-        elif key in device_data:
-            return device_data[key]
-        raise KeyError
-    
-    return OrderedDict([(key, get_from_stack(key)) for key in data_keys])
+    args.distributed_rank = distributed_init(args)
+
+    main(args, **kwargs)
+
+    if dist.is_initialized():
+        dist.barrier(get_global_group())
+
+def call_main(args, main, **kwargs):
+    if args.world_size > 1:
+        infer_init_method(args)
+        args.distributed_rank = None
+        torch.multiprocessing.spawn(
+            fn=distributed_main,
+            args=(main, args, kwargs),
+            nprocs=min(
+                torch.cuda.device_count(),
+                args.world_size
+            ),
+            join=True
+        )
+    else:
+        args.distributed_rank = 0
+        main(args, **kwargs)
+
+def batch_all_gather(tensor, group, return_tensor=False):
+    """Perform an all-gather operation considering tensors with different batch size"""
+    world_size = get_world_size(group=group)
+    rank = get_rank(group=group)
+
+    size_list = [
+        tensor.new_zeros(tensor.dim(), dtype=torch.int64) for _ in range(world_size)
+    ]
+    local_size = tensor.new_tensor(tensor.shape, dtype=torch.int64)
+    dist.all_gather(size_list, local_size, group=group)
+
+    max_size = torch.stack(size_list).max(dim=0)[0][0]
+    size_offsets = [max_size - size[0] for size in size_list]
+
+    if local_size[0] != max_size:
+        offset = torch.cat(
+            (
+                tensor.new_tensor([max_size - local_size[0]]),
+                local_size[1:]
+            )
+        )
+        padding = tensor.new_zeros(tuple(int(dim) for dim in offset), dtype=torch.uint8)
+        tensor = torch.cat((tensor, padding), dim=0)
+
+    tensor_list = [
+        tensor if i == rank else torch.empty_like(tensor) for i in range(world_size)
+    ]
+    dist.all_gather(tensor_list, tensor, group=group)
+    tensor_list = [
+        tensor[:max_size-size_offsets[i]] for i, tensor in enumerate(tensor_list)
+    ]
+    if return_tensor:
+        return torch.stack(tensor_list, dim=0)
+    else:
+        return tensor_list
+
+
+def all_gather(tensor, group, return_tensor = False):
+    """Perform an all-gather operation."""
+    world_size = get_world_size(group = group)
+    rank = get_rank(group = group)
+    tensor_list = [
+        tensor if i == rank else torch.empty_like(tensor) for i in range(world_size)
+    ]
+    dist.all_gather(tensor_list, tensor, group = group)
+    if return_tensor:
+        return torch.stack(tensor_list, dim = 0)
+    else:
+        return tensor_list
\ No newline at end of file
diff --git a/utils/pdb.py b/utils/pdb.py
old mode 100644
new mode 100755
diff --git a/utils/trainer_utils.py b/utils/trainer_utils.py
old mode 100644
new mode 100755
index 7eac9a5..0393ae3
--- a/utils/trainer_utils.py
+++ b/utils/trainer_utils.py
@@ -10,9 +10,39 @@ import wandb
 from torch.nn.parallel.data_parallel import DataParallel
 from torch.nn.parallel import DistributedDataParallel
 import torch.nn as nn
+from dataclasses import dataclass
 
 logger = logging.getLogger(__name__)
 
+@dataclass
+class Task:
+    name: str
+    num_classes: int
+    property: str
+
+
+def get_task(pred_task, src_data):
+    final_acuity = 8
+
+    imminent_discharge = 8
+
+    diagnosis = 17
+
+    return {
+        'mortality': Task('mortality', 1, 'binary'),
+        'long_term_mortality': Task('long_term_mortality', 1, 'binary'), 
+        'los_3day': Task('los_3day', 1, 'binary'), 
+        'los_7day': Task('los_7day', 1, 'binary'),
+        'readmission': Task('readmission', 1, 'binary'),
+        'final_acuity': Task('final_acuity', final_acuity, 'multi-class'), 
+        'imminent_discharge': Task('imminent_discharge', imminent_discharge, 'multi-class'), 
+        'diagnosis': Task('diagnosis', diagnosis, 'multi-label'), 
+        'creatinine': Task('creatinine', 5, 'multi-class'), 
+        'bilirubin': Task('bilirubin', 5, 'multi-class'), 
+        'platelets': Task('platelets', 5, 'multi-class'),
+        'wbc': Task('wbc', 3, 'multi-class'),
+    }[pred_task]
+
 class WarmupConstantSchedule(torch.optim.lr_scheduler.LambdaLR):
     def __init__(self, optimizer, warmup_steps, last_epoch=-1):
 
@@ -103,7 +133,7 @@ def model_save(model, path, n_epoch, optimizer):
                  'optimizer_state_dict': optimizer.state_dict()},
                 path
     )
-    print(f'model save at : {path})
+    print(f'model save at : {path}')
 
 
 def log_from_dict(metric_dict, data_type, data_name, n_epoch):
diff --git a/utils/utils.py b/utils/utils.py
old mode 100644
new mode 100755
index 8ceae2e..1369d9d
--- a/utils/utils.py
+++ b/utils/utils.py
@@ -74,4 +74,157 @@ def move_to_cpu(sample):
         if tensor.dtype in {torch.bfloat16, torch.float16}:
             tensor = tensor.to(dtype=torch.float32)
         return tensor.cpu()
-    return apply_to_sample(_move_to_cpu, sample)
\ No newline at end of file
+    return apply_to_sample(_move_to_cpu, sample)
+
+
+import logging
+from contextlib import contextmanager
+
+import torch
+import torch.nn.functional as F
+
+logger = logging.getLogger(__name__)
+
+def item(tensor):
+    if hasattr(tensor, "item"):
+        return tensor.item()
+    if hasattr(tensor, "__getitem__"):
+        return tensor[0]
+    return tensor
+
+def get_rng_state():
+    state = {"torch_rng_state": torch.get_rng_state()}
+    if torch.cuda.is_available():
+        state["cuda_rng_state"] = torch.cuda.get_rng_state()
+    return state
+
+def set_rng_state(state):
+    torch.set_rng_state(state["torch_rng_state"])
+    if torch.cuda.is_available():
+        torch.cuda.set_rng_state(state["cuda_rng_state"])
+
+class set_torch_seed(object):
+    def __init__(self, seed):
+        assert isinstance(seed, int)
+        self.rng_state = get_rng_state()
+
+        torch.manual_seed(seed)
+        if torch.cuda.is_available():
+            torch.cuda.manual_seed(seed)
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *exc):
+        set_rng_state(self.rng_state)
+
+
+def should_stop_early(patience, dataname, metric: float, descending=True) -> bool:
+    is_better = lambda x,y: x < y if descending else x > y
+
+    prev_best = getattr(should_stop_early, "best", {})
+    
+    if len(prev_best.keys())==0:
+        should_stop_early.best={}
+        should_stop_early.num_runs={}
+        
+    if dataname not in prev_best.keys() or is_better(metric, prev_best[dataname]):
+        should_stop_early.best[dataname] = metric
+        should_stop_early.num_runs[dataname] = 0
+        print(f"{dataname} Patience decreased to ", should_stop_early.num_runs[dataname])
+        return False
+    else:
+        should_stop_early.num_runs[dataname] += 1
+        print(f"{dataname} Patience increased to ", should_stop_early.num_runs[dataname])
+        if should_stop_early.num_runs[dataname] >= patience:
+            print("early stop since valid performance hasn't improved for last {} runs".format(
+                    patience
+                )
+            )
+            return True
+        else:
+            return False
+
+def apply_to_sample(f, sample):
+    if hasattr(sample, "__len__") and len(sample) == 0:
+        return {}
+    
+    def _apply(x):
+        if torch.is_tensor(x):
+            return f(x)
+        elif isinstance(x, dict):
+            return {key: _apply(value) for key, value in x.items()}
+        elif isinstance(x, list):
+            return [_apply(x) for x in x]
+        elif isinstance(x, tuple):
+            return tuple(_apply(x) for x in x)
+        elif isinstance(x, set):
+            return {_apply(x) for x in x}
+        else:
+            return x
+    
+    return _apply(sample)
+
+def move_to_cuda(sample, device=None):
+    device = device or torch.cuda.current_device()
+
+    def _move_to_cuda(tensor):
+        return tensor.to(device=device, non_blocking=True)
+    
+    return apply_to_sample(_move_to_cuda, sample)
+
+def move_to_cpu(sample):
+    def _move_to_cpu(tensor):
+        if tensor.dtype in {torch.bfloat16, torch.float16}:
+            tensor = tensor.to(dtype=torch.float32)
+        return tensor.cpu()
+    return apply_to_sample(_move_to_cpu, sample)
+
+def prepare_sample(sample):
+    if torch.cuda.is_available():
+        sample = move_to_cuda(sample)
+    
+    return sample
+
+class CudaEnvironment(object):
+    def __init__(self):
+        cur_device = torch.cuda.current_device()
+        prop = torch.cuda.get_device_properties("cuda:{}".format(cur_device))
+        self.name = prop.name
+        self.major = prop.major
+        self.minor = prop.minor
+        self.total_memory_in_GB = prop.total_memory / 1024 / 1024 / 1024
+
+    @staticmethod
+    def pretty_print_cuda_env_list(cuda_env_list):
+        """
+        Given a list of CudaEnviorments, pretty print them
+        """
+        num_workers = len(cuda_env_list)
+        center = "CUDA enviroments for all {} workers".format(num_workers)
+        banner_len = 40 - len(center) // 2
+        first_line = "*" * banner_len + center + "*" * banner_len
+        logger.info(first_line)
+        for r, env in enumerate(cuda_env_list):
+            logger.info(
+                "rank {:3d}: ".format(r)
+                + "capabilities = {:2d}.{:<2d} ; ".format(env.major, env.minor)
+                + "total memory = {:.3f} GB ; ".format(env.total_memory_in_GB)
+                + "name = {:40s}".format(env.name)
+            )
+        logger.info(first_line)
+
+def has_parameters(module):
+    try:
+        next(module.parameters())
+        return True
+    except StopIteration:
+        return False
+
+@contextmanager
+def rename_logger(logger, new_name):
+    old_name = logger.name
+    if new_name is not None:
+        logger.name = new_name
+    yield logger
+    logger.name = old_name
\ No newline at end of file
